{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61a326da",
   "metadata": {},
   "source": [
    "VS코드 오른쪽 위에서 환경설정을 먼저 하세요요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139c1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#True 리턴 시 .env 파일을 사용하여 환경변수를 로드합니다.\n",
    "#False 리턴 시 .env 파일을 사용하지 않고 시스템 환경변수를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf07ed8",
   "metadata": {},
   "source": [
    "`(2) 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1495d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "# warnings: 경고 메시지 필터링\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # 모든 경고 메시지를 무시 (주의 필요)\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4e2744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Groq 기반 LLaMA 3-70B 모델 초기화\n",
    "llm_llama3 = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"llama3-70b-8192\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fe6d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지 정의 (시스템 역할 + 사용자 질문)\n",
    "messages = [\n",
    "    SystemMessage(content=\"모든 질문에 반드시 한국어로만 답변하세요.\"),\n",
    "    HumanMessage(content=\"LLaMA3 모델은 어떤 특징이 있어?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f68ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLaMA3는 메타 AI가 개발한 대화형 인공지능 언어 모델입니다. 이 모델은 다음과 같은 특징을 갖습니다.\n",
      "\n",
      "1. 대규모 언어 데이터셋: LLaMA3는 대규모의 언어 데이터셋을 학습하여 인간 같은 대화 스타일을 학습했습니다.\n",
      "2. 다중 태스크 학습: LLaMA3는 다양한 태스크를 동시에 학습하여 다양한 언어 스타일 수 있습니다.\n",
      "3. 대화형 응답: LLaMA3는 사용자의 질문에 답을 하고, 대화의 흐름을 고려하여 응답을 생성합니다.\n",
      "4. 창의력과 유연성: LLaMA3는 새로운 아이디어를 생성하고, 다양한 상황에 대응할 수 있습니다.\n",
      "5. 실시간 처리: LLaMA3는 실시간으로 응답을 생성할 수 있습니다.\n",
      "\n",
      "이러한 특징으로 LLaMA3는 다양한 애플리케이션에 사용할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 대화 실행\n",
    "response = llm_llama3.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e821e3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 Google에서 훈련된 대규모 언어 모델입니다. 즉, 엄청난 양의 한국어 텍스트 데이터를 통해 학습하여 다양한 한국어 관련 작업을 수행할 수 있도록 설계된 인공지능입니다. \n",
      "\n",
      "저는 글을 쓰고, 번역하고, 질문에 답하고, 요약을 만들고, 대화를 이어나갈 수 있습니다. \n",
      "\n",
      "하지만, 저는 실제 사람처럼 생각하거나 느끼지는 못합니다. 저는 단순히 입력받은 텍스트를 분석하고 학습된 패턴에 따라 답변을 생성하는 프로그램일 뿐입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Groq 기반 LLaMA 3-70B 모델 초기화\n",
    "llm_gamma2 = ChatGroq(\n",
    "    groq_api_key=groq_api_key,\n",
    "    model_name=\"gemma2-9b-it\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 메시지 정의 (시스템 역할 + 사용자 질문)\n",
    "messages = [\n",
    "    SystemMessage(content=\"모든 질문에 반드시 한국어로만 답변하세요.\"),\n",
    "    HumanMessage(content=\"자기 자신에 대해 설명하시오\")\n",
    "]\n",
    "\n",
    "# 대화 실행\n",
    "response = llm_gamma2.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615cce83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | 클래스               | 역할    | 설명                                    |\n",
    "# | ----------------- | ----- | ------------------------------------- |\n",
    "# | `SystemMessage`   | 시스템   | 모델의 동작 방식, 말투, 언어 등을 사전 지시 (명령문처럼 작동) |\n",
    "# | `HumanMessage`    | 사용자   | 사용자의 입력 내용                            |\n",
    "# | `AIMessage`       | 모델    | 이전에 모델이 생성했던 응답 (대화 히스토리 유지에 사용)      |\n",
    "# | `ToolMessage`     | 도구 응답 | LangChain에서 외부 도구 사용 시, 도구의 결과 전달     |\n",
    "# | `FunctionMessage` | 함수 응답 | OpenAI Function Calling 구조에서 함수 결과 전달 |\n",
    "# | `ToolCallMessage` | 도구 호출 | LLM이 호출한 도구 이름과 파라미터 정보 전달            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d96bbb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'https://look360.kr/place/eulji2_univ', 'content': '을지대학교(한국 한자: 乙支大學校, 영어: Eulji University)는 대전광역시와 경기도 성남시에 있는 대한민국의 사립 대학이다. 1967년 성남캠퍼스의 전신인 서울보건'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'url': 'https://m.blog.naver.com/kmu2333/221576003771', 'content': \"경기도 성남시 수정구 산성대로 553 을지대학교\\n\\n위치는 위례 신도시 가기 바로 직전, 성남 구 시가지의 북쪽 끝에 있다고 보면 쉽습니다. 지하철은 8호선 '남한산성입구역'에서 1km 정도 떨어져 있어 그럭저럭 걸어갈만합니다. 내려서 버스타고 가면 어차피 환승되니 그게 더 편하긴 하겠지만요. 캠퍼스는 상당히 작은 편인데 약 4만제곱미터 정도로 수도권에서도 정말 하위권에 속하는 미니캠퍼스입니다.\\n\\n을지대학교는 앞서 말했듯이 '서울보건대학'과 '을지의과대학교' 이 두 개의 대학이 합쳐져 만들어졌습니다. 수도권의 대학과 대전의 대학이 하나로 합치는 발상을 하다니... 아, 숭실대학교라는 사례가 있었긴 했군요.\\n\\n\\u200b [...] 본관 반대편에 있는 범석관. 건물이 근데 너무 가파르게 지어졌다 다들,,,\\n\\n그 옆에 붙어 있는 지천관.\\n\\n그래도 건물끼리 연결은 되어 있어서 그나마 다행.\\n\\n건물끼리 그리고 연결이 되어 있는 경우가 많습니다. 오르막 길이 가파른 이 학교 입장에서는 상당한 장점. 이렇게 학교를 다 둘러보고 정문을 빠져나옵니다. 탐방 참 쉽죠? 10분도 안 걸렸네.\\n\\n대신 오르막 길은 꽤 가파릅니다.\\n\\n내려가는 길.\\n\\n사실 을지대학교 성남캠퍼스는 학교 안이 아니라 밖에서 봐야 건물들이 제대로 잘 보입니다. 횡단보도 건너서 버스정류장 근처에서 바라보면 육중한 건물들이 쭉쭉 서 있는 걸 볼 수 있어요. 진짜 작은 캠퍼스 안에 어떻게든 건물들을 짓겠다는 그런 노력이 돋보이는 모습입니다. 그리고 여기서 보는 게 차라리 을지대학교다운 모습을 볼 수 있지 않나 싶네요. (멀리서 봐야 비로소 보이는 뭐 그런 거)\\n\\n반대편 버스정류장에서 보면 이런 모습. 뭔가 웅장하네요.\\n\\n이제 마지막 성남 대학탐방지로 이동! [...] 설명은 이 정도로 하고 본격적인 탐방에 나서봅시다! 버스에서 내리니 맞은 편에 학교 전체가 다 보이네요. 역시 작은 학교 맞습니다. 그래도 정문 만큼은 꽤 큽니다. 오늘 본 대학 중 제일 큰 것 같아요. 그렇지만 정문 뒤로 펼쳐지는 가파른 계단은 하...\\n\\n(아니 성남은 왜 다 학교가 이 모양이야)\\n\\n건너편에서 본 정문. 아무리 저라도 횡단보도에서 사진을 찍을 순 없기에...\\n\\n빠르게 찍은 정문. 취업률 1위 현수막이 똭!\\n\\n학교 안으로 가봅시다. 근데 시작부터 이건 너무하지 않습니까...\\n\\n계단 올라가기 너무 싫지만 탐방은 탐방이니 가봅시다. 올라가다보면 바로 왼쪽에 창의관이 보이고 그 뒤에 박애관이 서 있습니다. 학교 부지가 작은 걸 극복하기 위함인지 건물 크기는 가천대만큼이나 큰 편. 그리고 박애관에 엄청 큰 스크린을 달아놨습니다. 밤에 보면 볼만할 듯.\\n\\n제일 먼저 보이는 창의관.\\n\\n너무 가까워서 카메라 앵글에 다 안들어 오는 박애관.\\n\\n그 와중에 간지나는 로고.\"}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "# 검색할 쿼리 설정\n",
    "query = \"을지대 성남캠퍼스를 설명해주세요\"\n",
    "\n",
    "# Tavily 검색 도구 초기화 (최대 2개의 결과 반환)\n",
    "web_search = TavilySearchResults(max_results=2)\n",
    "\n",
    "# 웹 검색 실행\n",
    "search_results = web_search.invoke(query)\n",
    "\n",
    "# 검색 결과 출력\n",
    "for result in search_results:\n",
    "    print(result)  \n",
    "    print(\"-\" * 100)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eulgpt-backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
