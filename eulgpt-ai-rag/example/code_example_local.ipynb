{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08870a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# # 1. ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸° (ì§€ê¸ˆ ìˆëŠ” íŒŒì¼)\n",
    "# loader = DirectoryLoader(\n",
    "#     path=\"data\",              # ì´ í´ë” ì•ˆì˜\n",
    "#     glob=\"**/*.txt\",                      # ëª¨ë“  .txt íŒŒì¼\n",
    "#     loader_cls=TextLoader,                # íŒŒì¼ í•˜ë‚˜ë‹¹ TextLoader ì‚¬ìš©\n",
    "#     loader_kwargs={\"encoding\": \"utf-8\"}\n",
    "# )\n",
    "\n",
    "loader = TextLoader(\"data/ì„ì§€ëŒ€_í•™ì—…ì„±ì ì²˜ë¦¬ê·œì •.txt\", encoding=\"utf-8\")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d1c7936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ë¬¸ì„œ ìª¼ê°œê¸°\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99104fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ì„ë² ë”© ëª¨ë¸ (Ollama ì‚¬ìš©)\n",
    "# ollama pull bge-m3\n",
    "embedding = OllamaEmbeddings(model=\"bge-m3\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d33d409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Chroma ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥\n",
    "vectordb = Chroma.from_documents(\n",
    "    docs,\n",
    "    embedding=embedding,\n",
    "    persist_directory=\"example_code/chroma_grade_rules\"\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff9ceb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. LLM (ë„ˆì˜ ëª¨ë¸)\n",
    "# ollama run joonoh/HyperCLOVAX-SEED-Text-Instruct-1.5B\n",
    "llm = ChatOllama(model=\"joonoh/HyperCLOVAX-SEED-Text-Instruct-1.5B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57027f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. RetrievalQA êµ¬ì„±\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectordb.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6b91920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ ë‹µë³€:\n",
      "ì¬ìˆ˜ê°•ì€ ì´ 24í•™ì ê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë‹¤ë§Œ, í•œ í•™ê¸°ì— í•™ì ì·¨ì†Œë¥¼ ìœ„í•œ ì¬ìˆ˜ê°•ì‹ ì²­ì€ 6í•™ì  ì´ë‚´ì— í•œí•˜ì—¬ í—ˆìš©ë©ë‹ˆë‹¤. (2017í•™ë…„ë„ ì‹ ì…ìƒë¶€í„°ëŠ” ì¬í•™ì—°í•œ ì´ë‚´ ì´ 24í•™ì ê¹Œì§€ ì‹ ì²­ê°€ëŠ¥í•˜ë©°, í•œ í•™ê¸°ë‹¹ 2ê³¼ëª©ìœ¼ë¡œ ì œí•œí•©ë‹ˆë‹¤.)\n",
      "\n",
      "ğŸ“š ì°¸ê³  ë¬¸ì„œ (ìš”ì•½):\n",
      "- â‘¡ í¸ì…í•™ìƒì— ëŒ€í•˜ì—¬ëŠ” ì „ì  ëŒ€í•™ì—ì„œ ì´ìˆ˜í•œ êµê³¼ëª© ë° í•™ì ì„ ì‹¬ì‚¬í•˜ì—¬ ë³¸ ëŒ€í•™ì—\n",
      "- [ì œëª©ê°œì • 2025.1.15.]\n",
      "- ë“±ê¸‰ 20ëª… ì´í•˜ 21ëª… ì´ìƒ\n"
     ]
    }
   ],
   "source": [
    "# 7. ì˜ˆì‹œ ì§ˆì˜\n",
    "query = \"ì¬ìˆ˜ê°•ì€ ìµœëŒ€ ëª‡ í•™ì ê¹Œì§€ ê°€ëŠ¥í•œê°€ìš”?\"\n",
    "result = qa_chain.invoke(query)\n",
    "\n",
    "# 8. ì¶œë ¥\n",
    "print(\"ğŸ“Œ ë‹µë³€:\")\n",
    "print(result[\"result\"])\n",
    "\n",
    "print(\"\\nğŸ“š ì°¸ê³  ë¬¸ì„œ (ìš”ì•½):\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(\"-\", doc.page_content.strip().split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02749372",
   "metadata": {},
   "source": [
    "# RAG ì‹œìŠ¤í…œ ê°œì„  ë°©ë²•ë“¤\n",
    "\n",
    "ë‹µë³€ ì •í™•ë„ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•œ ì—¬ëŸ¬ ë°©ë²•ë“¤ì„ ì ìš©í•´ë³´ê² ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. **ë” ë‚˜ì€ í…ìŠ¤íŠ¸ ë¶„í• **: ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„í• \n",
    "2. **ê°œì„ ëœ ê²€ìƒ‰**: ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ë°˜ í•„í„°ë§\n",
    "3. **ë” ë‚˜ì€ í”„ë¡¬í”„íŠ¸**: ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•œ êµ¬ì²´ì ì¸ ì§€ì‹œ\n",
    "4. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: í‚¤ì›Œë“œ + ì˜ë¯¸ ê²€ìƒ‰ ê²°í•©\n",
    "5. **ë‹µë³€ ê²€ì¦**: ì†ŒìŠ¤ ë¬¸ì„œì™€ì˜ ì¼ì¹˜ì„± í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ebd89f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ì¡´ ë¬¸ì„œ ìˆ˜: 10\n",
      "ê°œì„ ëœ ë¬¸ì„œ ìˆ˜: 20\n",
      "\n",
      "ì²« ë²ˆì§¸ ì²­í¬ ì˜ˆì‹œ:\n",
      "í•™ì—…ì„±ì ì²˜ë¦¬ê·œì •\n",
      "ì œì • 2007. 3. 1.\n",
      "ê°œì • 2015. 3. 1.\n",
      "ê°œì • 2017. 3. 1.\n",
      "ê°œì • 2017. 9. 1.\n",
      "ê°œì • 2018. 9. 1.\n",
      "ê°œì • 2020. 3. 1.\n",
      "ê°œì • 2022. 2. 1.\n",
      "ê°œì • 2023. 3. 1.\n",
      "ê°œì • 2024. 3. 1.\n",
      "ê°œì • 2024. 4. 1.\n",
      "ê°œì • 2025. 1.15.\n",
      "ì œ1ì¡°(ëª©ì ) ì´ ê·œì •ì€ ì„ì§€ëŒ€í•™êµ(ì´í•˜ â€œë³¸êµ...\n"
     ]
    }
   ],
   "source": [
    "## ê°œì„  ë°©ë²• 1: ë” ë‚˜ì€ í…ìŠ¤íŠ¸ ë¶„í• \n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import re\n",
    "\n",
    "def smart_text_splitter(documents):\n",
    "    \"\"\"ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¬¸ì„œë¥¼ ë¶„í• í•˜ëŠ” ê°œì„ ëœ í•¨ìˆ˜\"\"\"\n",
    "    # í•œêµ­ì–´ ë¬¸ì„œì— ë§ëŠ” êµ¬ë¶„ì ì„¤ì •\n",
    "    korean_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=300,  # ë” ì‘ì€ ì²­í¬ í¬ê¸°\n",
    "        chunk_overlap=100,  # ë” í° ì˜¤ë²„ë©\n",
    "        separators=[\n",
    "            \"\\n\\n\",  # ë‹¨ë½ êµ¬ë¶„\n",
    "            \"\\n\",    # ì¤„ë°”ê¿ˆ\n",
    "            \"ã€‚\",     # ë§ˆì¹¨í‘œ\n",
    "            \".\",\n",
    "            \" \",     # ê³µë°±\n",
    "            \"\"\n",
    "        ],\n",
    "        keep_separator=True\n",
    "    )\n",
    "    \n",
    "    return korean_splitter.split_documents(documents)\n",
    "\n",
    "# ê°œì„ ëœ ë¶„í•  ì ìš©\n",
    "improved_docs = smart_text_splitter(documents)\n",
    "print(f\"ê¸°ì¡´ ë¬¸ì„œ ìˆ˜: {len(docs)}\")\n",
    "print(f\"ê°œì„ ëœ ë¬¸ì„œ ìˆ˜: {len(improved_docs)}\")\n",
    "print(f\"\\nì²« ë²ˆì§¸ ì²­í¬ ì˜ˆì‹œ:\")\n",
    "print(improved_docs[0].page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04bea440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°œì„ ëœ ë²¡í„°ìŠ¤í† ì–´ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "## ê°œì„  ë°©ë²• 2: ìƒˆë¡œìš´ ë²¡í„°ìŠ¤í† ì–´ êµ¬ì„±\n",
    "\n",
    "# ê°œì„ ëœ ë¬¸ì„œë¡œ ìƒˆë¡œìš´ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±\n",
    "improved_vectordb = Chroma.from_documents(\n",
    "    improved_docs,\n",
    "    embedding=embedding,\n",
    "    persist_directory=\"example_code/chroma_grade_rules_improved\"\n",
    ")\n",
    "improved_vectordb.persist()\n",
    "\n",
    "print(\"ê°œì„ ëœ ë²¡í„°ìŠ¤í† ì–´ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad9706fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ ì ìš©ëœ RAG ì²´ì¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "## ê°œì„  ë°©ë²• 3: ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# ë” êµ¬ì²´ì ì¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±\n",
    "custom_prompt = PromptTemplate(\n",
    "    template=\"\"\"ë‹¹ì‹ ì€ ì„ì§€ëŒ€í•™êµ í•™ì—…ì„±ì ì²˜ë¦¬ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  êµ¬ì²´ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë¬¸ì„œ ë‚´ìš©:\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ë‹µë³€ ê°€ì´ë“œë¼ì¸:\n",
    "1. ë¬¸ì„œì— ëª…ì‹œëœ ì •í™•í•œ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”\n",
    "2. í•™ì , ê¸°ê°„, ì¡°ê±´ ë“± ìˆ«ì ì •ë³´ëŠ” ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”\n",
    "3. ê´€ë ¨ ì¡°í•­ì´ë‚˜ ì˜ˆì™¸ì‚¬í•­ì´ ìˆë‹¤ë©´ í•¨ê»˜ ì–¸ê¸‰í•˜ì„¸ìš”\n",
    "4. í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” \"ë¬¸ì„œì—ì„œ ëª…í™•íˆ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"ë¼ê³  ë§í•˜ì„¸ìš”\n",
    "\n",
    "ë‹µë³€:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ… í•¨ìˆ˜\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# ê°œì„ ëœ RAG ì²´ì¸ ìƒì„±\n",
    "improved_rag_chain = (\n",
    "    {\"context\": improved_vectordb.as_retriever(search_kwargs={\"k\": 5}) | format_docs, \n",
    "     \"question\": RunnablePassthrough()}\n",
    "    | custom_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ ì ìš©ëœ RAG ì²´ì¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdcecd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í–¥ìƒëœ ê²€ìƒ‰ í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "## ê°œì„  ë°©ë²• 4: ìœ ì‚¬ë„ ì ìˆ˜ ê¸°ë°˜ í•„í„°ë§\n",
    "\n",
    "def enhanced_retrieval(query, vectorstore, threshold=0.5, k=5):\n",
    "    \"\"\"ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ í–¥ìƒëœ ê²€ìƒ‰\"\"\"\n",
    "    # similarity_search_with_scoreë¥¼ ì‚¬ìš©í•˜ì—¬ ì ìˆ˜ì™€ í•¨ê»˜ ê²€ìƒ‰\n",
    "    docs_with_scores = vectorstore.similarity_search_with_score(query, k=k*2)\n",
    "    \n",
    "    # ì„ê³„ê°’ë³´ë‹¤ ë†’ì€ ì ìˆ˜ì˜ ë¬¸ì„œë§Œ í•„í„°ë§\n",
    "    filtered_docs = [doc for doc, score in docs_with_scores if score > threshold]\n",
    "    \n",
    "    # ìƒìœ„ kê°œ ë¬¸ì„œë§Œ ë°˜í™˜\n",
    "    return filtered_docs[:k]\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í•¨ìˆ˜\n",
    "def test_enhanced_qa(query, vectorstore, custom_prompt, llm):\n",
    "    \"\"\"ê°œì„ ëœ QA ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    # í–¥ìƒëœ ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    relevant_docs = enhanced_retrieval(query, vectorstore)\n",
    "    \n",
    "    if not relevant_docs:\n",
    "        return \"ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.\"\n",
    "    \n",
    "    # ë¬¸ì„œ ë‚´ìš© í¬ë§·íŒ…\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    \n",
    "    # í”„ë¡¬í”„íŠ¸ì— ì…ë ¥\n",
    "    prompt_input = custom_prompt.format(context=context, question=query)\n",
    "    \n",
    "    # LLM í˜¸ì¶œ\n",
    "    response = llm.invoke(prompt_input)\n",
    "    \n",
    "    return response.content if hasattr(response, 'content') else str(response)\n",
    "\n",
    "print(\"í–¥ìƒëœ ê²€ìƒ‰ í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e366c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ì§ˆë¬¸: ì¬ìˆ˜ê°•ì€ ìµœëŒ€ ëª‡ í•™ì ê¹Œì§€ ê°€ëŠ¥í•œê°€ìš”?\n",
      "==================================================\n",
      "ğŸ“‹ ê¸°ì¡´ ì‹œìŠ¤í…œ ë‹µë³€:\n",
      "ì¬ìˆ˜ê°•ì€ ìµœëŒ€ 2íšŒê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤. í•œ í•™ê¸°ì— í•™ì ì·¨ì†Œë¥¼ ìœ„í•œ ì¬ìˆ˜ê°•ì‹ ì²­ì€ 6í•™ì  ì´ë‚´ì— í•œí•˜ì—¬ í—ˆìš©ë˜ë©°, 3ê³¼ëª©ì„ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (2017í•™ë…„ë„ ì‹ ì…ìƒë¶€í„°ëŠ” ì¬í•™ì—°í•œ ì´ë‚´ ì´ 24í•™ì ê¹Œì§€ ì‹ ì²­ê°€ëŠ¥í•˜ë©°, í•œ í•™ê¸°ë‹¹ 2ê³¼ëª©ìœ¼ë¡œ ì œí•œ)\n",
      "\n",
      "âœ¨ ê°œì„ ëœ ì‹œìŠ¤í…œ ë‹µë³€:\n",
      "ì¬ìˆ˜ê°•ìœ¼ë¡œ ì·¨ë“í•œ í•™ì ì˜ ìµœëŒ€ ìˆ˜ëŠ” ë¬¸ì„œì— ëª…ì‹œë˜ì–´ ìˆëŠ” ë°”ì™€ ê°™ìŠµë‹ˆë‹¤. \n",
      "\n",
      "2017ë…„ë„ ê°œì • ê·œì •ì— ë”°ë¥´ë©´ í•œ í•™ê¸°ì— í•™ì ì·¨ì†Œë¥¼ ìœ„í•œ ì¬ìˆ˜ê°•ì‹ ì²­ì€ 6í•™ì  ì´ë‚´ì—ë§Œ í—ˆìš©ë˜ë©°, ì´ ì¤‘ í•œ í•™ê¸°ë‹¹ ê³¼ëª© ìˆ˜ì—ëŠ” ì œí•œì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "- ë”°ë¼ì„œ, 2017ë…„ë„ë¶€í„° ì¬í•™ì—°í•œ ì‹ í•™ìƒì¼ ê²½ìš° ì´ 24í•™ì ê¹Œì§€ ì¬ìˆ˜ê°• ì‹ ì²­ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. \n",
      "- ê·¸ë¦¬ê³  í•´ë‹¹ ì¸ë±ìŠ¤ì˜ í•™ìƒ ê°œê°œì¸ì€ í•œ í•™ê¸°ì— ìµœëŒ€ 2ê³¼ëª©ê¹Œì§€ë§Œ ì¬ìˆ˜ê°• ì‹ ì²­ì´ ê°€ëŠ¥í•œ ê²ƒìœ¼ë¡œ ì•Œê³  ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ì œ4ì¡°ì™€ ì œ5ì¡°ë¥¼ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤:\n",
      "\n",
      "(ì œ4ì¡°) ì •í•´ì§„ ì”ì—¬ ê³¼ì •ì€ ìˆ˜ê°•ì„ ì‹ ì²­í•˜ì—¬ ì´ìˆ˜í•˜ë„ë¡ í•˜ì—¬ì•¼ í•œë‹¤.\n",
      "\n",
      "(ì œ5ì¡°) \n",
      "â‘  í•™ì¹™ ì‹œí–‰ ì„¸ì¹™ ì œ32ì¡°ì— ì˜í•˜ì—¬ êµê³¼ëª©ì„ ë‹´ë‹¹í•œ êµìˆ˜ëŠ” í‰ê°€ëœ ì„±ì ì„ ë§¤ í•™ê¸° ì§€ì •ëœ ê¸°ê°„ ë‚´ì— êµë¬´í˜ì‹ ì²˜ì— ì œì¶œí•˜ì—¬ì•¼ í•œë‹¤.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ê°œì„  ë°©ë²• 5: ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë° ë¹„êµ\n",
    "\n",
    "# ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ê°œì„ ëœ ì‹œìŠ¤í…œ ë¹„êµ\n",
    "test_queries = [\n",
    "    \"ì¬ìˆ˜ê°•ì€ ìµœëŒ€ ëª‡ í•™ì ê¹Œì§€ ê°€ëŠ¥í•œê°€ìš”?\",\n",
    "    \"ì„±ì  ê²½ê³ ëŠ” ì–¸ì œ ë°›ë‚˜ìš”?\",\n",
    "    \"í•™ì  ì·¨ì†ŒëŠ” ëª‡ ê³¼ëª©ê¹Œì§€ ê°€ëŠ¥í•œê°€ìš”?\",\n",
    "    \"ì¡¸ì—… í‰ì ì€ ì–´ë–»ê²Œ ê³„ì‚°í•˜ë‚˜ìš”?\"\n",
    "]\n",
    "\n",
    "def compare_systems(query):\n",
    "    \"\"\"ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ê°œì„ ëœ ì‹œìŠ¤í…œ ë¹„êµ\"\"\"\n",
    "    print(f\"ğŸ” ì§ˆë¬¸: {query}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # ê¸°ì¡´ ì‹œìŠ¤í…œ\n",
    "    original_result = qa_chain.invoke(query)\n",
    "    print(\"ğŸ“‹ ê¸°ì¡´ ì‹œìŠ¤í…œ ë‹µë³€:\")\n",
    "    print(original_result[\"result\"])\n",
    "    print()\n",
    "    \n",
    "    # ê°œì„ ëœ ì‹œìŠ¤í…œ\n",
    "    improved_answer = improved_rag_chain.invoke(query)\n",
    "    print(\"âœ¨ ê°œì„ ëœ ì‹œìŠ¤í…œ ë‹µë³€:\")\n",
    "    print(improved_answer)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# ì²« ë²ˆì§¸ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
    "compare_systems(test_queries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a230996",
   "metadata": {},
   "source": [
    "# ì¶”ê°€ ê°œì„  ë°©ë²•ë“¤\n",
    "\n",
    "ë‹µë³€ ì •í™•ë„ë¥¼ ë”ìš± í–¥ìƒì‹œí‚¤ê¸° ìœ„í•œ ì¶”ê°€ ë°©ë²•ë“¤:\n",
    "\n",
    "## 6. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + ë²¡í„° ê²€ìƒ‰)\n",
    "í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ê³¼ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ì„ ê²°í•©í•˜ì—¬ ë” ì •í™•í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "## 7. ë¬¸ì„œ ì „ì²˜ë¦¬ ê°œì„ \n",
    "- í•œêµ­ì–´ íŠ¹ì„±ì— ë§ëŠ” í…ìŠ¤íŠ¸ ì •ê·œí™”\n",
    "- ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°\n",
    "- ë¬¸ë‹¨ êµ¬ì¡° ê°œì„ \n",
    "\n",
    "## 8. ë‹µë³€ í›„ì²˜ë¦¬\n",
    "- ë‹µë³€ì˜ ì¼ê´€ì„± ê²€ì¦\n",
    "- ì¤‘ë³µ ì •ë³´ ì œê±°\n",
    "- êµ¬ì¡°í™”ëœ ë‹µë³€ í¬ë§·\n",
    "\n",
    "## 9. í‰ê°€ ë©”íŠ¸ë¦­ ë„ì…\n",
    "- ë‹µë³€ í’ˆì§ˆ ìë™ í‰ê°€\n",
    "- ì†ŒìŠ¤ ë¬¸ì„œì™€ì˜ ì¼ì¹˜ë„ ì¸¡ì •\n",
    "- ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68601b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ê°œì„  ë°©ë²• 6: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„\n",
    "\n",
    "# BM25 ì„¤ì¹˜ê°€ í•„ìš”í•œ ê²½ìš° ì£¼ì„ í•´ì œ\n",
    "# !pip install rank_bm25\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "import re\n",
    "\n",
    "def preprocess_korean_text(text):\n",
    "    \"\"\"í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\"\"\"\n",
    "    # íŠ¹ìˆ˜ë¬¸ì ì œê±°\n",
    "    text = re.sub(r'[^\\w\\sê°€-í£]', ' ', text)\n",
    "    # ì—°ì†ëœ ê³µë°± ì œê±°\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def hybrid_search(query, vectorstore, documents, k=5):\n",
    "    \"\"\"ë²¡í„° ê²€ìƒ‰ê³¼ BM25ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\"\"\"\n",
    "    \n",
    "    # 1. ë²¡í„° ê²€ìƒ‰\n",
    "    vector_docs = vectorstore.similarity_search_with_score(query, k=k*2)\n",
    "    \n",
    "    # 2. BM25 ê²€ìƒ‰ ì¤€ë¹„\n",
    "    doc_texts = [preprocess_korean_text(doc.page_content) for doc in documents]\n",
    "    tokenized_docs = [text.split() for text in doc_texts]\n",
    "    \n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "    \n",
    "    # 3. BM25 ê²€ìƒ‰\n",
    "    query_tokens = preprocess_korean_text(query).split()\n",
    "    bm25_scores = bm25.get_scores(query_tokens)\n",
    "    \n",
    "    # 4. ì ìˆ˜ ê²°í•© (ê°€ì¤‘í‰ê· )\n",
    "    combined_results = []\n",
    "    \n",
    "    for i, (doc, vector_score) in enumerate(vector_docs):\n",
    "        # ë¬¸ì„œ ì¸ë±ìŠ¤ ì°¾ê¸°\n",
    "        doc_idx = None\n",
    "        for j, orig_doc in enumerate(documents):\n",
    "            if orig_doc.page_content == doc.page_content:\n",
    "                doc_idx = j\n",
    "                break\n",
    "        \n",
    "        if doc_idx is not None:\n",
    "            # ë²¡í„° ì ìˆ˜ë¥¼ 0-1ë¡œ ì •ê·œí™” (ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜)\n",
    "            normalized_vector_score = 1 / (1 + vector_score)\n",
    "            # BM25 ì ìˆ˜ ì •ê·œí™”\n",
    "            max_bm25 = max(bm25_scores) if max(bm25_scores) > 0 else 1\n",
    "            normalized_bm25_score = bm25_scores[doc_idx] / max_bm25\n",
    "            \n",
    "            # ê°€ì¤‘ ê²°í•© (ë²¡í„° 70%, BM25 30%)\n",
    "            combined_score = 0.7 * normalized_vector_score + 0.3 * normalized_bm25_score\n",
    "            \n",
    "            combined_results.append((doc, combined_score))\n",
    "    \n",
    "    # ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "    combined_results.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return [doc for doc, _ in combined_results[:k]]\n",
    "\n",
    "print(\"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8f55fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°œì„ ëœ ì„¤ì •ë“¤ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "## ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­ë“¤\n",
    "\n",
    "# 1. ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ ì¡°ì •\n",
    "def test_different_k_values(query):\n",
    "    \"\"\"ì„œë¡œ ë‹¤ë¥¸ k ê°’ìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ ë¹„êµ\"\"\"\n",
    "    print(f\"ì§ˆë¬¸: {query}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for k in [3, 5, 7]:\n",
    "        retriever = improved_vectordb.as_retriever(search_kwargs={\"k\": k})\n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        print(f\"k={k}ì¼ ë•Œ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}\")\n",
    "        print(f\"ì²« ë²ˆì§¸ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°: {docs[0].page_content[:100]}...\")\n",
    "        print()\n",
    "\n",
    "# 2. ìœ ì‚¬ë„ ì„ê³„ê°’ ì¡°ì •\n",
    "def test_similarity_threshold(query):\n",
    "    \"\"\"ìœ ì‚¬ë„ ì„ê³„ê°’ìœ¼ë¡œ í’ˆì§ˆ ê°œì„ \"\"\"\n",
    "    docs_with_scores = improved_vectordb.similarity_search_with_score(query, k=10)\n",
    "    \n",
    "    print(f\"ì§ˆë¬¸: {query}\")\n",
    "    print(\"ë¬¸ì„œë³„ ìœ ì‚¬ë„ ì ìˆ˜:\")\n",
    "    for i, (doc, score) in enumerate(docs_with_scores):\n",
    "        print(f\"{i+1}. ì ìˆ˜: {score:.3f} - {doc.page_content[:80]}...\")\n",
    "    \n",
    "    # ì„ê³„ê°’ 0.8 ì´í•˜ì˜ ë¬¸ì„œë§Œ ì‚¬ìš©\n",
    "    filtered_docs = [doc for doc, score in docs_with_scores if score <= 0.8]\n",
    "    print(f\"\\nì„ê³„ê°’(0.8) ì ìš© í›„ ë¬¸ì„œ ìˆ˜: {len(filtered_docs)}\")\n",
    "    \n",
    "    return filtered_docs\n",
    "\n",
    "# 3. ë” êµ¬ì²´ì ì¸ í”„ë¡¬í”„íŠ¸ ê°œì„ \n",
    "better_prompt = PromptTemplate(\n",
    "    template=\"\"\"ë‹¹ì‹ ì€ ì„ì§€ëŒ€í•™êµ í•™ì—…ì„±ì ì²˜ë¦¬ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸:\n",
    "{context}\n",
    "\n",
    "ì‚¬ìš©ì ì§ˆë¬¸: {question}\n",
    "\n",
    "ë‹µë³€ ìš”êµ¬ì‚¬í•­:\n",
    "1. ë°˜ë“œì‹œ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”\n",
    "2. ì •í™•í•œ ì¡°í•­ ë²ˆí˜¸, í•™ì  ìˆ˜, ê¸°ê°„ ë“±ì„ ëª…ì‹œí•˜ì„¸ìš”\n",
    "3. ì˜ˆì™¸ì‚¬í•­ì´ë‚˜ ì¶”ê°€ ì¡°ê±´ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”\n",
    "4. ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”\n",
    "5. ë‹µë³€ í˜•ì‹: \"ê·œì •ì— ë”°ë¥´ë©´...\" ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”\n",
    "\n",
    "ì •í™•í•œ ë‹µë³€:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "print(\"ê°œì„ ëœ ì„¤ì •ë“¤ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef99ce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ìµœì¢… ê°œì„ ëœ ì‹œìŠ¤í…œ ë‹µë³€:\n",
      "==================================================\n",
      "ê·œì •ì— ë”°ë¥´ë©´ í•œ í•™ê¸°ì— í•™ì ì·¨ì†Œë¥¼ ìœ„í•œ ì¬ìˆ˜ê°•ì‹ ì²­ì€ 6í•™ì  ì´ë‚´ì— í•œí•˜ì—¬ í—ˆìš©ë˜ë‚˜, 3ê³¼ëª©ì„ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ë‹¨, 2017í•™ë…„ë„ ì‹ ì…ìƒë¶€í„°ëŠ” ì¬í•™ì—°í•œ ì´ë‚´ ì´ 24í•™ì ê¹Œì§€ ì‹ ì²­ê°€ëŠ¥í•˜ë©°, í•œ í•™ê¸°ë‹¹ 2ê³¼ëª©ìœ¼ë¡œ ì œí•œí•©ë‹ˆë‹¤)\n",
      "==================================================\n",
      "\n",
      "ğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ ìœ ì‚¬ë„ ì ìˆ˜:\n",
      "1. ì ìˆ˜: 372.964\n",
      "   ë‚´ìš©: 3-3-14~2\n",
      "ì„œ ìš”êµ¬ë˜ëŠ” êµê³¼ëª© ë° í•™ì ë§Œ ì¸ì •í•˜ê³  ì •í•´ì§„ ì”ì—¬ ê³¼ì •ì€ ìˆ˜ê°•ì„ ì‹ ì²­í•˜ì—¬ ì´ìˆ˜í•˜ë„ë¡ í•˜ì—¬ì•¼ í•œë‹¤.\n",
      "â‘¢ ì •í•´ì§„ í•™ì ë¯¸ë‹¬ë¡œ ì¡¸ì—…ì´ ë³´ë¥˜ëœ ìëŠ” í•™ì  ë¯¸ì·¨ë“ ê³¼ëª©ì— í•œí•˜ì—¬ ì¬ìˆ˜ê°•ì„ ì‹ ì²­í•˜ì—¬ì•¼ í•œë‹¤.\n",
      "â‘£ í•œ í•™ê¸°ì— í•™ì ì·¨ì†Œë¥¼ ìœ„í•œ ì¬ìˆ˜ê°•ì‹ ì²­ì€ 6í•™ì  ì´ë‚´ì— ...\n",
      "\n",
      "2. ì ìˆ˜: 471.119\n",
      "   ë‚´ìš©: ì´í•˜ì˜ ì„±ì )ì„ ë°˜ì˜í•˜ì§€ ì•ŠëŠ”ë‹¤(ë‹¨, 2019í•™ë…„ë„ë¶€í„° ìˆ˜ê°•í•œ ê³¼ëª©ì— ëŒ€í•´ì„œ ì¬ìˆ˜ê°• ì‹ ì²­ê°€ëŠ¥ ì„±ì ì„ C0ë“±ê¸‰ ì´í•˜ë¡œ ì œí•œí•œë‹¤). (ê°œì • 2017.9.1., 2020.3.1.)\n",
      "â‘¡ ì¬ìˆ˜ê°•ìœ¼ë¡œ ì·¨ë“í•œ í•™ì ì€ ì„±ì ë“±ê¸‰ì´ B+ë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ë‹¤. (ê°œì • 2017.9.1.)\n",
      "â‘¢...\n",
      "\n",
      "3. ì ìˆ˜: 509.087\n",
      "   ë‚´ìš©: â‘¤ ì„±ì ê¸°ì¤€ì„ ë³€ê²½í•  ì‹œì—ëŠ” ë°˜ë“œì‹œ êµë¬´í˜ì‹ ì²˜ë¥¼ ê±°ì³ ì´ì¥ì˜ ìŠ¹ì¸ì„ ì–»ì–´ì•¼ í•œë‹¤.\n",
      "(ì‹ ì„¤ 2017.3.1.)(ê°œì • 2024.4.1.)\n",
      "ì œ4ì¡°(ì¬ìˆ˜ê°•ìì˜ ìˆ˜ê°•ì‹ ì²­) â‘  ì¬ìˆ˜ê°• ì‹ ì²­ì„ í•˜ì§€ ì•Šê³  ìˆ˜ê°•ì„ í•œ êµê³¼ëª©ì€ ì´ìœ ì—¬í•˜ë¥¼ ë§‰ë¡ í•˜ê³  ê·¸ ì„±ì ì„ ì¸ì •í•˜ì§€ ì•ŠëŠ”ë‹¤.\n",
      "â‘¡ í¸ì…í•™...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë¡œ ìƒˆë¡œìš´ ì²´ì¸ ìƒì„±\n",
    "best_rag_chain = (\n",
    "    {\"context\": improved_vectordb.as_retriever(search_kwargs={\"k\": 3}) | format_docs, \n",
    "     \"question\": RunnablePassthrough()}\n",
    "    | better_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ìµœì¢… ê°œì„ ëœ ì‹œìŠ¤í…œìœ¼ë¡œ í…ŒìŠ¤íŠ¸\n",
    "query = \"ì¬ìˆ˜ê°•ì€ ìµœëŒ€ ëª‡ í•™ì ê¹Œì§€ ê°€ëŠ¥í•œê°€ìš”?\"\n",
    "\n",
    "print(\"ğŸš€ ìµœì¢… ê°œì„ ëœ ì‹œìŠ¤í…œ ë‹µë³€:\")\n",
    "print(\"=\"*50)\n",
    "final_answer = best_rag_chain.invoke(query)\n",
    "print(final_answer)\n",
    "print(\"=\"*50)\n",
    "\n",
    "# ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ìœ ì‚¬ë„ ì ìˆ˜ë„ í™•ì¸\n",
    "print(\"\\nğŸ“Š ê²€ìƒ‰ëœ ë¬¸ì„œ ìœ ì‚¬ë„ ì ìˆ˜:\")\n",
    "docs_with_scores = improved_vectordb.similarity_search_with_score(query, k=3)\n",
    "for i, (doc, score) in enumerate(docs_with_scores):\n",
    "    print(f\"{i+1}. ì ìˆ˜: {score:.3f}\")\n",
    "    print(f\"   ë‚´ìš©: {doc.page_content[:150]}...\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
