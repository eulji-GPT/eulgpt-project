{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57936702",
   "metadata": {},
   "source": [
    "# 📚 RAG 시스템 완전 정복: 을GPT 0주차 \n",
    "\n",
    "을GPT ai및rag팀을 위한 노트북입니다.\n",
    "공유를 금지합니다. \n",
    "\n",
    "## 🎯 학습 목표\n",
    "\n",
    "이 노트북을 통해 다음을 배울 수 있습니다:\n",
    "\n",
    "### 📖 이론적 이해\n",
    "- ✅ RAG(Retrieval-Augmented Generation)의 핵심 개념\n",
    "- ✅ 임베딩과 벡터 검색의 원리\n",
    "- ✅ 프롬프트 엔지니어링 기법\n",
    "- ✅ AI 시스템 평가 및 개선 방법\n",
    "\n",
    "### 🛠️ 실무적 기술\n",
    "- ✅ Google Gemini API 활용법\n",
    "- ✅ LangChain 프레임워크 사용법\n",
    "- ✅ 벡터 데이터베이스(Chroma) 구축\n",
    "- ✅ 실제 문서를 활용한 QA 시스템 개발\n",
    "\n",
    "## 📋 노트북 구성\n",
    "\n",
    "| 단계 | 제목 | 주요 내용 | 소요 시간 |\n",
    "|------|------|-----------|-----------|\n",
    "| **1️⃣** | 환경 설정 | 라이브러리 import, API 설정 | 5분 |\n",
    "| **2️⃣** | 문서 로딩 | 텍스트 파일 불러오기 | 5분 |\n",
    "| **3️⃣** | 텍스트 분할 | 문서를 적절한 크기로 나누기 | 10분 |\n",
    "| **4️⃣** | 임베딩 생성 | 텍스트를 벡터로 변환 | 10분 |\n",
    "| **5️⃣** | 벡터DB 구축 | 검색 가능한 데이터베이스 생성 | 10분 |\n",
    "| **6️⃣** | RAG 체인 구성 | 검색+생성 파이프라인 구축 | 15분 |\n",
    "| **7️⃣** | 프롬프트 최적화 | 답변 품질 향상 | 15분 |\n",
    "| **8️⃣** | 성능 평가 | 시스템 테스트 및 개선 | 10분 |\n",
    "\n",
    "**총 소요 시간: 약 80분** ⏰\n",
    "\n",
    "## 🚀 시작하기 전에\n",
    "\n",
    "### 📋 사전 요구사항\n",
    "\n",
    "**필수 지식**:\n",
    "- 기본적인 Python 문법\n",
    "- Jupyter Notebook 사용법\n",
    "- API 개념에 대한 이해\n",
    "\n",
    "**준비사항**:\n",
    "- Google AI Studio 계정 및 API 키\n",
    "- Python 환경 (Python 3.8+)\n",
    "- 필요한 패키지 설치\n",
    "\n",
    "### 💡 학습 방법\n",
    "\n",
    "1. **순서대로 실행**: 셀을 위에서부터 차례대로 실행하세요\n",
    "2. **마크다운 정독**: 각 코드 전에 있는 설명을 꼼꼼히 읽어보세요\n",
    "3. **실험해보기**: 매개변수를 바꿔가며 결과 변화를 관찰하세요\n",
    "4. **질문하기**: 이해가 안 되는 부분은 주저하지 말고 질문하세요\n",
    "\n",
    "**이제 AI의 미래 기술인 RAG를 함께 배워봅시다!** 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae1ae67",
   "metadata": {},
   "source": [
    "# 🤖 Google Gemini API를 활용한 RAG(Retrieval-Augmented Generation) 시스템 구축\n",
    "\n",
    "## 📚 RAG란 무엇인가요?\n",
    "\n",
    "**RAG(Retrieval-Augmented Generation)**는 대화형 AI의 새로운 패러다임입니다.\n",
    "\n",
    "### 🔍 기존 AI와 RAG의 차이점\n",
    "\n",
    "| 구분 | 기존 AI 모델 | RAG 시스템 |\n",
    "|------|-------------|------------|\n",
    "| **정보 소스** | 훈련 데이터에만 의존 | 외부 문서 + 훈련 데이터 |\n",
    "| **최신성** | 훈련 시점까지의 정보 | 실시간 문서 업데이트 가능 |\n",
    "| **정확성** | 할루시네이션 발생 가능 | 문서 기반의 정확한 답변 |\n",
    "| **투명성** | 답변 근거 불명확 | 참고 문서 출처 제공 |\n",
    "| **전문성** | 일반적인 지식 | 특정 도메인 전문 지식 |\n",
    "\n",
    "### 🎯 RAG의 동작 원리\n",
    "\n",
    "1. **📄 문서 준비**: 전문 문서들을 시스템에 입력\n",
    "2. **✂️ 문서 분할**: 큰 문서를 작은 청크(조각)로 나눔\n",
    "3. **🧮 임베딩 변환**: 텍스트를 벡터(숫자 배열)로 변환\n",
    "4. **💾 벡터 저장**: 벡터들을 데이터베이스에 저장\n",
    "5. **🔍 유사도 검색**: 질문과 관련된 문서 조각 찾기\n",
    "6. **🤖 답변 생성**: 찾은 문서와 질문을 AI에게 제공하여 답변 생성\n",
    "\n",
    "### 💡 이 노트북에서 학습할 내용\n",
    "\n",
    "- Google Gemini API 설정 방법\n",
    "- 문서 로딩 및 전처리 기술\n",
    "- 임베딩과 벡터 데이터베이스 이해\n",
    "- RAG 체인 구성 및 최적화\n",
    "- 실제 질의응답 시스템 구현\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ 사전 준비사항\n",
    "\n",
    "### 1. API 키 설정\n",
    "```bash\n",
    "# .env 파일에 다음 내용 추가\n",
    "GOOGLE_API_KEY=your_google_api_key_here\n",
    "```\n",
    "\n",
    "### 2. 필요한 라이브러리\n",
    "- `langchain`: RAG 시스템 구축 프레임워크\n",
    "- `langchain-google-genai`: Google Gemini API 연동\n",
    "- `chromadb`: 벡터 데이터베이스\n",
    "- `python-dotenv`: 환경변수 관리\n",
    "\n",
    "### 3. 학습 데이터\n",
    "- `data/을지대_학업성적처리규정.txt`: 예시 문서\n",
    "\n",
    "---\n",
    "\n",
    "**🚀 이제 실제 RAG 시스템을 단계별로 구축해보겠습니다!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812fa5bf",
   "metadata": {},
   "source": [
    "## 🔍 RAG란 무엇인가요?\n",
    "\n",
    "**RAG (Retrieval-Augmented Generation)**는 대화형 AI의 한계를 극복하기 위한 혁신적인 기술입니다.\n",
    "\n",
    "### 📊 기존 LLM vs RAG 비교\n",
    "\n",
    "| 특징 | 기존 LLM | RAG 시스템 |\n",
    "|------|----------|------------|\n",
    "| **정보 소스** | 훈련 데이터만 사용 | 외부 문서 + 훈련 데이터 |\n",
    "| **최신 정보** | 훈련 시점까지만 | 실시간 문서 검색 가능 |\n",
    "| **정확성** | 할루시네이션 발생 가능 | 근거 기반 답변 |\n",
    "| **맞춤화** | 어려움 | 도메인 특화 가능 |\n",
    "\n",
    "### 🏗️ RAG 시스템 구조\n",
    "\n",
    "```\n",
    "1. 📄 문서 수집 → 2. ✂️ 텍스트 분할 → 3. 🧮 임베딩 생성 → 4. 💾 벡터DB 저장\n",
    "                                                    ↓\n",
    "6. 🤖 AI 답변 생성 ← 5. 🔍 유사 문서 검색 ← 사용자 질문\n",
    "```\n",
    "\n",
    "### 💡 RAG가 중요한 이유\n",
    "\n",
    "1. **정확성 향상**: 실제 문서를 기반으로 답변 생성\n",
    "2. **최신 정보**: 새로운 문서 추가만으로 지식 업데이트\n",
    "3. **투명성**: 답변의 근거가 되는 문서 확인 가능\n",
    "4. **비용 효율성**: 전체 모델 재훈련 없이 지식 확장\n",
    "\n",
    "이제 실제 코드로 RAG 시스템을 구축해보겠습니다! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f305c8f3",
   "metadata": {},
   "source": [
    "# 1️⃣ 라이브러리 Import 및 초기 설정\n",
    "\n",
    "## 📦 필요한 라이브러리들\n",
    "\n",
    "RAG 시스템을 구축하기 위해 다음 라이브러리들을 사용합니다:\n",
    "\n",
    "### 🔧 기본 유틸리티\n",
    "- **`os`**: 운영체제 관련 기능 (파일 경로, 환경변수 등)\n",
    "- **`dotenv`**: `.env` 파일에서 환경변수를 안전하게 로드\n",
    "\n",
    "### 📄 문서 처리\n",
    "- **`TextLoader`**: 텍스트 파일을 불러오는 도구\n",
    "- **`RecursiveCharacterTextSplitter`**: 문서를 작은 조각으로 나누는 도구\n",
    "\n",
    "### 🗄️ 벡터 데이터베이스\n",
    "- **`Chroma`**: 임베딩 벡터를 저장하고 검색하는 데이터베이스\n",
    "\n",
    "### 🤖 Google Gemini API\n",
    "- **`ChatGoogleGenerativeAI`**: Google Gemini 언어모델\n",
    "- **`GoogleGenerativeAIEmbeddings`**: Google 임베딩 모델\n",
    "- **`RetrievalQA`**: 검색 기반 질의응답 체인\n",
    "\n",
    "## 🔐 환경변수 설정의 중요성\n",
    "\n",
    "```python\n",
    "load_dotenv()  # .env 파일에서 GOOGLE_API_KEY 로드\n",
    "```\n",
    "\n",
    "이 코드는 프로젝트 루트의 `.env` 파일에서 API 키를 자동으로 읽어옵니다. \n",
    "API 키를 코드에 직접 작성하지 않아 보안을 유지할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f59650",
   "metadata": {},
   "source": [
    "## 🌟 Google Gemini API 소개\n",
    "\n",
    "### 왜 Google Gemini API를 사용하나요?\n",
    "\n",
    "**Google Gemini**는 Google의 최신 멀티모달 AI 모델로, RAG 시스템 구축에 매우 적합합니다.\n",
    "\n",
    "### 🎯 Gemini API의 주요 장점\n",
    "\n",
    "| 특징 | 설명 | RAG에서의 활용 |\n",
    "|------|------|---------------|\n",
    "| **고품질 임베딩** | `text-embedding-004` 모델 | 문서를 벡터로 변환 |\n",
    "| **강력한 언어 모델** | `gemini-1.5-flash` | 검색된 문서 기반 답변 생성 |\n",
    "| **한국어 지원** | 뛰어난 한국어 이해 능력 | 한국어 문서 처리에 최적 |\n",
    "| **비용 효율성** | 합리적인 API 가격 | 실험 및 학습에 적합 |\n",
    "\n",
    "### 🔧 필요한 구성 요소\n",
    "\n",
    "1. **임베딩 모델**: 텍스트를 숫자 벡터로 변환\n",
    "   - 문서와 질문을 같은 벡터 공간에 매핑\n",
    "   - 유사도 계산으로 관련 문서 찾기\n",
    "\n",
    "2. **언어 모델**: 검색된 정보를 바탕으로 답변 생성\n",
    "   - 자연스러운 한국어 답변 생성\n",
    "   - 문맥을 이해하고 적절한 응답 제공\n",
    "\n",
    "### 📋 사전 준비사항\n",
    "\n",
    "- slack으로 API키를 제공해드렸습니다. \n",
    "- 환경변수 설정 또는 직접 입력\n",
    "- 필요한 Python 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08870a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\geon1\\anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\geon1\\anaconda3\\envs\\langgraph_agent\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Google Gemini API 전용 RAG 시스템\n",
      "   - Google Gemini LLM (gemini-1.5-flash)\n",
      "   - Google 임베딩 (text-embedding-004)\n",
      "   - 환경 변수 로드 완료\n",
      "\n",
      "📄 문서 로딩 완료: 1개 문서\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ Google Gemini API 전용 RAG 시스템\")\n",
    "print(\"   - Google Gemini LLM (gemini-1.5-flash)\")\n",
    "print(\"   - Google 임베딩 (text-embedding-004)\")\n",
    "print(\"   - 환경 변수 로드 완료\")\n",
    "\n",
    "# 문서 불러오기\n",
    "loader = TextLoader(\"data/을지대_학업성적처리규정.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "print(f\"\\n📄 문서 로딩 완료: {len(documents)}개 문서\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1c7936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 문서 쪼개기\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c975b92",
   "metadata": {},
   "source": [
    "# 2️⃣ 문서 로딩 및 전처리\n",
    "\n",
    "## 📄 문서 로딩이란?\n",
    "\n",
    "RAG 시스템의 첫 번째 단계는 **지식 베이스가 될 문서들을 시스템에 로드**하는 것입니다.\n",
    "\n",
    "### 🎯 문서 로딩의 목적\n",
    "\n",
    "- **외부 지식 활용**: AI가 알지 못하는 최신 정보나 전문 지식 제공\n",
    "- **도메인 특화**: 특정 분야(예: 대학 규정)에 특화된 정보 활용\n",
    "- **정확성 향상**: 실제 문서를 기반으로 한 신뢰할 수 있는 답변\n",
    "\n",
    "### 📂 지원하는 파일 형식\n",
    "\n",
    "| 형식 | Loader | 특징 |\n",
    "|------|--------|------|\n",
    "| **TXT** | `TextLoader` | 일반 텍스트 파일 |\n",
    "| **PDF** | `PyPDFLoader` | PDF 문서 |\n",
    "| **Word** | `Docx2txtLoader` | Word 문서 |\n",
    "| **웹페이지** | `WebBaseLoader` | HTML 페이지 |\n",
    "| **CSV** | `CSVLoader` | 표 형태 데이터 |\n",
    "\n",
    "### 📖 이번 예제에서 사용할 문서\n",
    "\n",
    "- **을지대 학칙**: 대학의 기본 규정\n",
    "- **학업성적처리규정**: 성적 관련 세부 규칙\n",
    "\n",
    "이 문서들을 통해 대학 규정에 대한 질문답변 시스템을 만들어보겠습니다!\n",
    "\n",
    "# 2️⃣ 문서 분할 (Text Splitting)\n",
    "\n",
    "## 🔪 문서를 왜 쪼개야 할까요?\n",
    "\n",
    "RAG 시스템에서 문서 분할은 매우 중요한 단계입니다:\n",
    "\n",
    "### ❌ 문서를 통째로 사용할 때의 문제점\n",
    "1. **메모리 한계**: 대용량 문서는 AI 모델의 입력 길이 제한 초과\n",
    "2. **검색 정확도 저하**: 관련 없는 정보가 섞여 정확한 검색 어려움\n",
    "3. **처리 속도 느림**: 큰 문서 처리에 많은 시간 소요\n",
    "\n",
    "### ✅ 문서 분할의 장점\n",
    "1. **정확한 검색**: 질문과 가장 관련된 부분만 찾아서 사용\n",
    "2. **효율적 처리**: 작은 조각들로 빠른 검색 가능\n",
    "3. **메모리 효율성**: AI 모델의 제한된 컨텍스트 윈도우 내에서 동작\n",
    "\n",
    "## ⚙️ 분할 매개변수 이해하기\n",
    "\n",
    "```python\n",
    "RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,      # 각 조각의 최대 글자 수\n",
    "    chunk_overlap=50     # 인접한 조각 간 겹치는 글자 수\n",
    ")\n",
    "```\n",
    "\n",
    "- **`chunk_size`**: 한 조각의 크기 (너무 작으면 문맥 손실, 너무 크면 검색 부정확)\n",
    "- **`chunk_overlap`**: 조각 간 겹침 (문맥 연속성 유지, 정보 손실 방지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe6c6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 문서 수: 10\n",
      "개선된 문서 수: 20\n",
      "첫 번째 청크 예시:\n",
      "학업성적처리규정\n",
      "제정 2007. 3. 1.\n",
      "개정 2015. 3. 1.\n",
      "개정 2017. 3. 1.\n",
      "개정 2017. 9. 1.\n",
      "개정 2018. 9. 1.\n",
      "개정 2020. 3. 1.\n",
      "개정 2022. 2. 1.\n",
      "개정 2023. 3. 1.\n",
      "개정 2024. 3. 1.\n",
      "개정 2024. 4. 1.\n",
      "개정 2025. 1.15.\n",
      "제1조(목적) 이 규정은 을지대학교(이하 “본교...\n"
     ]
    }
   ],
   "source": [
    "# 개선된 텍스트 분할 (한국어 문서에 최적화)\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "def smart_text_splitter(documents):\n",
    "    \"\"\"의미 단위로 문서를 분할하는 개선된 함수\"\"\"\n",
    "    korean_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=300,  # 더 작은 청크 크기\n",
    "        chunk_overlap=100,  # 더 큰 오버랩\n",
    "        separators=[\n",
    "            \"\\n\\n\",  # 단락 구분\n",
    "            \"\\n\",    # 줄바꿈\n",
    "            \"。\",     # 마침표\n",
    "            \".\",\n",
    "            \" \",     # 공백\n",
    "            \"\"\n",
    "        ],\n",
    "        keep_separator=True\n",
    "    )\n",
    "    return korean_splitter.split_documents(documents)\n",
    "\n",
    "# 개선된 분할 적용\n",
    "improved_docs = smart_text_splitter(documents)\n",
    "print(f\"기존 문서 수: {len(docs)}\")\n",
    "print(f\"개선된 문서 수: {len(improved_docs)}\")\n",
    "print(f\"첫 번째 청크 예시:\")\n",
    "print(improved_docs[0].page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1795a09",
   "metadata": {},
   "source": [
    "### 📊 텍스트 분할 결과 분석\n",
    "\n",
    "위 코드에서 **기존 문서 수**와 **개선된 문서 수**를 비교해보세요:\n",
    "\n",
    "#### 🔍 분할 품질 체크리스트\n",
    "\n",
    "✅ **좋은 분할의 특징**:\n",
    "- 각 청크가 완전한 의미 단위를 포함\n",
    "- 중요한 정보가 여러 청크에 나뉘지 않음\n",
    "- 청크 간 적절한 중복으로 문맥 연결\n",
    "\n",
    "❌ **피해야 할 분할**:\n",
    "- 문장 중간에서 끊어짐\n",
    "- 너무 작아서 의미가 불분명\n",
    "- 너무 커서 관련 없는 내용 포함\n",
    "\n",
    "#### 💡 분할 최적화 팁\n",
    "\n",
    "```python\n",
    "# 한국어 문서에 최적화된 구분자 순서\n",
    "separators=[\n",
    "    \"\\n\\n\",     # 단락 구분 (최우선)\n",
    "    \"\\n\",       # 줄바꿈\n",
    "    \"。\",        # 마침표 (한국어)\n",
    "    \".\",        # 마침표 (영어)\n",
    "    \"?\", \"!\",   # 물음표, 감탄표\n",
    "    \";\", \",\",   # 세미콜론, 쉼표\n",
    "    \" \",        # 공백\n",
    "    \"\"          # 최후의 수단\n",
    "]\n",
    "```\n",
    "\n",
    "**다른 언어별 최적화**:\n",
    "- **영어**: `[\"\\n\\n\", \"\\n\", \".\", \"?\", \"!\", \";\", \",\", \" \", \"\"]`\n",
    "- **중국어**: `[\"\\n\\n\", \"\\n\", \"。\", \"？\", \"！\", \"；\", \"，\", \" \", \"\"]`\n",
    "- **일본어**: `[\"\\n\\n\", \"\\n\", \"。\", \"？\", \"！\", \"；\", \"、\", \" \", \"\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be94675c",
   "metadata": {},
   "source": [
    "# 3️⃣ 한국어 최적화 문서 분할\n",
    "\n",
    "## 🇰🇷 한국어 문서 처리의 특별함\n",
    "\n",
    "영어와 달리 한국어는 고유한 특성이 있어 특별한 처리가 필요합니다:\n",
    "\n",
    "### 📝 한국어 특성\n",
    "- **교착어**: 조사와 어미가 붙어 의미 변화\n",
    "- **띄어쓰기**: 영어와 다른 띄어쓰기 규칙\n",
    "- **문장 구조**: 주어-목적어-동사(SOV) 구조\n",
    "- **문서 형식**: 조항, 항, 호 등의 특별한 구조\n",
    "\n",
    "## ⚡ 개선된 분할 전략\n",
    "\n",
    "### 🔧 매개변수 최적화\n",
    "```python\n",
    "chunk_size=300     # 기존 500 → 300 (한국어는 더 작은 단위로)\n",
    "chunk_overlap=100  # 기존 50 → 100 (문맥 보존 강화)\n",
    "```\n",
    "\n",
    "### 📐 한국어 구분자 우선순위\n",
    "```python\n",
    "separators=[\n",
    "    \"\\n\\n\",    # 단락 구분 (가장 우선)\n",
    "    \"\\n\",      # 줄바꿈\n",
    "    \"。\",       # 한국어 마침표\n",
    "    \".\",       # 영어 마침표\n",
    "    \" \",       # 공백\n",
    "    \"\"         # 마지막 수단 (글자 단위 분할)\n",
    "]\n",
    "```\n",
    "\n",
    "이 순서대로 문서를 나누어 의미 단위를 최대한 보존합니다.\n",
    "\n",
    "# 3️⃣ 텍스트 분할 (Text Splitting)\n",
    "\n",
    "## ✂️ 왜 텍스트를 분할해야 할까요?\n",
    "\n",
    "긴 문서를 그대로 사용하면 여러 문제가 발생합니다:\n",
    "\n",
    "### 🚫 문제점들\n",
    "\n",
    "| 문제 | 설명 | 해결책 |\n",
    "|------|------|--------|\n",
    "| **토큰 제한** | AI 모델의 입력 길이 제한 | 적절한 크기로 분할 |\n",
    "| **검색 정확도** | 관련 없는 내용이 섞임 | 의미 단위로 분할 |\n",
    "| **처리 속도** | 큰 텍스트는 처리가 느림 | 작은 청크로 나누기 |\n",
    "\n",
    "### 🛠️ 분할 전략\n",
    "\n",
    "**RecursiveCharacterTextSplitter**의 동작 원리:\n",
    "1. **문단 단위** 분할 시도 (`\\n\\n`)\n",
    "2. **문장 단위** 분할 시도 (`\\n`)\n",
    "3. **단어 단위** 분할 시도 (` `)\n",
    "4. **글자 단위** 최종 분할\n",
    "\n",
    "### ⚙️ 주요 매개변수\n",
    "\n",
    "- **chunk_size**: 각 청크의 최대 크기 (예: 1000자)\n",
    "- **chunk_overlap**: 청크 간 중복 영역 (예: 200자)\n",
    "  - 중복을 두는 이유: 문맥 연결성 유지\n",
    "\n",
    "### 💡 청크 크기 선택 가이드\n",
    "\n",
    "| 청크 크기 | 장점 | 단점 | 적합한 용도 |\n",
    "|-----------|------|------|-------------|\n",
    "| **작음 (500자)** | 정확한 검색 | 문맥 부족 | FAQ, 간단한 정보 |\n",
    "| **중간 (1000자)** | 균형 잡힌 성능 | - | 일반적인 문서 |\n",
    "| **큼 (2000자)** | 풍부한 문맥 | 노이즈 증가 | 복잡한 설명서 |\n",
    "\n",
    "## 📊 분할 결과 비교\n",
    "실행 후 다음을 확인할 수 있습니다:\n",
    "- 기존 방식 vs 개선된 방식의 조각 개수 차이\n",
    "- 더 세밀하고 의미 있는 단위로 분할된 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236451b",
   "metadata": {},
   "source": [
    "# Google Gemini 임베딩 모델 설정\n",
    "\n",
    "Google Gemini API를 사용한 고품질 임베딩 시스템입니다.\n",
    "\n",
    "## 📚 Google Embedding Models:\n",
    "\n",
    "1. **text-embedding-004** (최신, 사용 중)\n",
    "   - 768 차원\n",
    "   - 다국어 지원 (한국어 우수)\n",
    "   - 최고 성능\n",
    "   - 의미 검색에 최적화\n",
    "\n",
    "2. **text-embedding-gecko@003**\n",
    "   - 768 차원  \n",
    "   - 안정적인 성능\n",
    "\n",
    "3. **textembedding-gecko@001**\n",
    "   - 768 차원\n",
    "   - 이전 버전\n",
    "\n",
    "# 4️⃣ 임베딩(Embedding) 이해하기\n",
    "\n",
    "## 🧮 임베딩이란?\n",
    "\n",
    "**임베딩**은 텍스트를 컴퓨터가 이해할 수 있는 숫자 벡터로 변환하는 기술입니다.\n",
    "\n",
    "### 🔄 변환 과정\n",
    "```\n",
    "\"재수강 규정\" → [0.123, -0.456, 0.789, ...] (768개 숫자)\n",
    "```\n",
    "\n",
    "### 💡 임베딩의 핵심 특성\n",
    "1. **의미 보존**: 비슷한 의미의 텍스트는 비슷한 벡터값\n",
    "2. **수치 연산**: 벡터 간 거리 계산으로 유사도 측정\n",
    "3. **고차원**: 768차원으로 복잡한 의미 표현\n",
    "\n",
    "## 📐 유사도 계산 원리\n",
    "\n",
    "```python\n",
    "# 예시: 코사인 유사도\n",
    "similarity = cosine(vector1, vector2)\n",
    "# 1.0에 가까울수록 유사, 0에 가까울수록 다름\n",
    "```\n",
    "\n",
    "## 🌟 Google Embedding Models\n",
    "\n",
    "Google에서 제공하는 임베딩 모델들의 특징을 알아봅시다:\n",
    "\n",
    "### 📚 Available Models:\n",
    "\n",
    "| 모델명 | 차원 | 특징 | 추천 용도 |\n",
    "|--------|------|------|----------|\n",
    "| **text-embedding-004** | 768 | 최신, 최고 성능 | **⭐ 이번 실습에서 사용** |\n",
    "| text-embedding-gecko@003 | 768 | 안정적 성능 | 프로덕션 환경 |\n",
    "| textembedding-gecko@001 | 768 | 이전 버전 | 호환성 필요시 |\n",
    "\n",
    "### ✨ Google Embedding 장점:\n",
    "\n",
    "| 특징 | 설명 | 장점 |\n",
    "|------|------|------|\n",
    "| **품질** | 최신 AI 기술 적용 | 높은 정확도 |\n",
    "| **한국어 지원** | 다국어 훈련 데이터 | 한국어 문서 처리 우수 |\n",
    "| **벡터 차원** | 768차원 고밀도 표현 | 풍부한 의미 정보 |\n",
    "| **처리 방식** | 클라우드 API | 별도 설치 불필요 |\n",
    "| **의미 이해** | 문맥 고려 임베딩 | 단어 순서와 문맥 파악 |\n",
    "\n",
    "### 🎯 Task Type 이해\n",
    "\n",
    "```python\n",
    "task_type=\"retrieval_document\"  # 문서 검색에 최적화된 임베딩\n",
    "```\n",
    "\n",
    "다른 옵션들:\n",
    "- `retrieval_query`: 검색 쿼리 최적화\n",
    "- `semantic_similarity`: 의미 유사도 계산\n",
    "- `classification`: 텍스트 분류\n",
    "- `clustering`: 문서 군집화\n",
    "\n",
    "이제 Google의 강력한 임베딩 모델을 설정해보겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02a03084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ollama BGE-M3 임베딩 모델 설정 완료\n",
      "   - 모델: bge-m3\n",
      "   - 플랫폼: Ollama\n",
      "   - 로컬 실행\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "# Ollama BGE-M3 임베딩 모델 설정\n",
    "embedding = OllamaEmbeddings(\n",
    "    model=\"bge-m3\"\n",
    ")\n",
    "\n",
    "print(\"✅ Ollama BGE-M3 임베딩 모델 설정 완료\")\n",
    "print(\"   - 모델: bge-m3\")\n",
    "print(\"   - 플랫폼: Ollama\")\n",
    "print(\"   - 로컬 실행\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ee61b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Ollama BGE-M3 임베딩으로 벡터스토어 생성 중...\n",
      "✅ Ollama BGE-M3 임베딩 벡터스토어 생성 완료!\n",
      "   - 기본 벡터스토어: 10개 문서\n",
      "   - 개선 벡터스토어: 20개 문서\n",
      "   - 임베딩: BGE-M3 (Ollama)\n",
      "   - 저장 경로: example_code/chroma_grade_rules_ollama_bge*\n",
      "✅ Ollama BGE-M3 임베딩 벡터스토어 생성 완료!\n",
      "   - 기본 벡터스토어: 10개 문서\n",
      "   - 개선 벡터스토어: 20개 문서\n",
      "   - 임베딩: BGE-M3 (Ollama)\n",
      "   - 저장 경로: example_code/chroma_grade_rules_ollama_bge*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geon1\\AppData\\Local\\Temp\\ipykernel_34136\\2040840657.py:17: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  improved_vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "# 벡터스토어 생성 (Ollama BGE-M3 임베딩 사용)\n",
    "print(\"🔄 Ollama BGE-M3 임베딩으로 벡터스토어 생성 중...\")\n",
    "\n",
    "# 기본 벡터스토어 생성\n",
    "vectordb = Chroma.from_documents(\n",
    "    docs,\n",
    "    embedding=embedding,\n",
    "    persist_directory=\"example_code/chroma_grade_rules_ollama_bge\"\n",
    ")\n",
    "\n",
    "# 개선된 벡터스토어 생성 (더 세밀한 문서 분할)\n",
    "improved_vectordb = Chroma.from_documents(\n",
    "    improved_docs,\n",
    "    embedding=embedding,\n",
    "    persist_directory=\"example_code/chroma_grade_rules_ollama_bge_improved\"\n",
    ")\n",
    "improved_vectordb.persist()\n",
    "\n",
    "print(\"✅ Ollama BGE-M3 임베딩 벡터스토어 생성 완료!\")\n",
    "print(f\"   - 기본 벡터스토어: {len(docs)}개 문서\")\n",
    "print(f\"   - 개선 벡터스토어: {len(improved_docs)}개 문서\")\n",
    "print(f\"   - 임베딩: BGE-M3 (Ollama)\")\n",
    "print(f\"   - 저장 경로: example_code/chroma_grade_rules_ollama_bge*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b0103ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Google Gemini LLM 설정 완료\n",
      "   - 모델: gemini-1.5-flash\n",
      "   - 온도: 0.1 (정확한 답변 선호)\n",
      "✅ LangChain 모듈 및 유틸리티 함수 준비 완료\n"
     ]
    }
   ],
   "source": [
    "# Google Gemini LLM 설정\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "print(\"✅ Google Gemini LLM 설정 완료\")\n",
    "print(\"   - 모델: gemini-1.5-flash\")\n",
    "print(\"   - 온도: 0.1 (정확한 답변 선호)\")\n",
    "\n",
    "# LangChain 추가 모듈 import\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# 검색 결과 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "print(\"✅ LangChain 모듈 및 유틸리티 함수 준비 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb6776",
   "metadata": {},
   "source": [
    "# 6️⃣ 대화형 AI 모델 (LLM) 설정\n",
    "\n",
    "## 🤖 LLM이란?\n",
    "\n",
    "**LLM(Large Language Model)**은 대화형 AI의 핵심입니다. 방대한 텍스트 데이터로 훈련된 거대한 신경망 모델입니다.\n",
    "\n",
    "### 🧠 Google Gemini 1.5 Flash 특징\n",
    "\n",
    "| 특성 | 설명 | 장점 |\n",
    "|------|------|------|\n",
    "| **모델 크기** | 대규모 파라미터 | 높은 이해력과 생성 능력 |\n",
    "| **다국어** | 한국어 포함 100+ 언어 | 자연스러운 한국어 대화 |\n",
    "| **속도** | Flash 버전 | 빠른 응답 속도 |\n",
    "| **컨텍스트** | 긴 문맥 이해 | 복잡한 문서 처리 가능 |\n",
    "\n",
    "## ⚙️ LLM 설정 매개변수 이해\n",
    "\n",
    "```python\n",
    "ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.1,          # 창의성 vs 일관성\n",
    "    max_tokens=None,          # 응답 길이 제한 (None=무제한)\n",
    "    timeout=None,             # 응답 대기 시간\n",
    "    max_retries=2,            # 실패시 재시도 횟수\n",
    ")\n",
    "```\n",
    "\n",
    "### 🌡️ Temperature 매개변수\n",
    "- **0.0**: 매우 일관된, 예측 가능한 답변\n",
    "- **0.1**: 약간의 창의성, 대부분 일관됨 ← **우리 설정**\n",
    "- **0.5**: 균형잡힌 창의성과 일관성\n",
    "- **1.0**: 매우 창의적, 때로는 예측 불가능\n",
    "\n",
    "**💡 왜 0.1을 선택했을까요?**\n",
    "학업 규정과 같은 정확한 정보가 필요한 경우, 창의성보다는 일관성과 정확성이 중요하기 때문입니다.\n",
    "\n",
    "## 🔗 유틸리티 함수들\n",
    "\n",
    "### 📝 format_docs 함수\n",
    "```python\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "```\n",
    "검색된 여러 문서 조각들을 하나의 텍스트로 합치는 역할을 합니다.\n",
    "\n",
    "# 5️⃣ 벡터 데이터베이스 구축 (Vector Database)\n",
    "\n",
    "## 💾 벡터 데이터베이스란?\n",
    "\n",
    "벡터 데이터베이스는 **임베딩 벡터를 저장하고 빠르게 검색**할 수 있는 특수한 데이터베이스입니다.\n",
    "\n",
    "### 🏆 Chroma DB를 선택한 이유\n",
    "\n",
    "| 특징 | 설명 | 장점 |\n",
    "|------|------|------|\n",
    "| **경량성** | 별도 서버 불필요 | 학습용으로 완벽 |\n",
    "| **Python 친화적** | 간단한 API | 쉬운 사용법 |\n",
    "| **로컬 저장** | 파일 기반 저장 | 데이터 지속성 |\n",
    "| **무료** | 오픈소스 | 비용 부담 없음 |\n",
    "\n",
    "### 🔍 벡터 검색 과정\n",
    "\n",
    "```\n",
    "1. 사용자 질문: \"학점은 몇 점까지 인가요?\"\n",
    "           ↓\n",
    "2. 질문을 벡터로 변환: [0.2, -0.3, 0.7, ...]\n",
    "           ↓\n",
    "3. 유사한 벡터 검색: 코사인 유사도 계산\n",
    "           ↓\n",
    "4. 상위 k개 문서 반환: 가장 관련성 높은 청크들\n",
    "```\n",
    "\n",
    "### 📊 검색 알고리즘 비교\n",
    "\n",
    "| 방법 | 정확도 | 속도 | 메모리 사용량 |\n",
    "|------|--------|------|---------------|\n",
    "| **선형 검색** | 100% | 느림 | 적음 |\n",
    "| **근사 검색** | 95%+ | 빠름 | 보통 |\n",
    "| **HNSW** | 99%+ | 매우 빠름 | 많음 |\n",
    "\n",
    "### 🎯 검색 매개변수\n",
    "\n",
    "- **k**: 반환할 문서 개수 (보통 3-5개)\n",
    "- **score_threshold**: 최소 유사도 기준\n",
    "- **filter**: 메타데이터 기반 필터링\n",
    "\n",
    "### 💡 Pro Tip: 컬렉션 이름\n",
    "\n",
    "컬렉션 이름을 의미있게 지으면:\n",
    "- `eul_grade_rules`: 을지대 성적 규정\n",
    "- `company_policies`: 회사 정책\n",
    "- `product_manuals`: 제품 매뉴얼\n",
    "\n",
    "나중에 여러 도메인을 구분해서 관리할 수 있습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca253756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Google Gemini RAG 체인 생성 완료\n",
      "   - 기본 QA 체인: qa_chain (Google Gemini)\n",
      "   - 고급 RAG 체인: improved_rag_chain (Google Gemini)\n",
      "   - 검색 문서 수: 5개 (k=5)\n",
      "   - 임베딩: Google text-embedding-004\n",
      "   - LLM: Google Gemini 1.5 Flash\n"
     ]
    }
   ],
   "source": [
    "# Google Gemini RAG 체인 생성\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Google Gemini 기본 QA 체인\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=improved_vectordb.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Google Gemini용 커스텀 프롬프트 템플릿\n",
    "custom_prompt = PromptTemplate(\n",
    "    template=\"\"\"당신은 을지대학교 학업성적처리규정 전문가입니다. 주어진 문서를 바탕으로 정확하고 구체적인 답변을 제공해주세요.\n",
    "\n",
    "문서 내용:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변 가이드라인:\n",
    "1. 문서에 명시된 정확한 정보만 사용하세요\n",
    "2. 학점, 기간, 조건 등 숫자 정보는 정확히 인용하세요\n",
    "3. 관련 조항이나 예외사항이 있다면 함께 언급하세요\n",
    "4. 확실하지 않은 정보는 \"문서에서 명확히 확인할 수 없습니다\"라고 말하세요\n",
    "5. 답변은 \"규정에 따르면...\"으로 시작하세요\n",
    "\n",
    "답변:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# Google Gemini 고급 RAG 체인 생성\n",
    "improved_rag_chain = (\n",
    "    {\"context\": improved_vectordb.as_retriever(search_kwargs={\"k\": 5}) | format_docs, \n",
    "     \"question\": RunnablePassthrough()}\n",
    "    | custom_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"✅ Google Gemini RAG 체인 생성 완료\")\n",
    "print(\"   - 기본 QA 체인: qa_chain (Google Gemini)\")\n",
    "print(\"   - 고급 RAG 체인: improved_rag_chain (Google Gemini)\")\n",
    "print(\"   - 검색 문서 수: 5개 (k=5)\")\n",
    "print(\"   - 임베딩: Google text-embedding-004\")\n",
    "print(\"   - LLM: Google Gemini 1.5 Flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8309c83d",
   "metadata": {},
   "source": [
    "# 7️⃣ RAG 체인 구성의 핵심\n",
    "\n",
    "## 🔗 RAG 체인이란?\n",
    "\n",
    "RAG 체인은 **검색(Retrieval)**과 **생성(Generation)**을 연결하는 파이프라인입니다.\n",
    "\n",
    "### 🎯 RAG 동작 플로우\n",
    "\n",
    "```mermaid\n",
    "질문 입력 → 벡터 검색 → 관련 문서 추출 → 프롬프트 생성 → LLM 답변 → 최종 응답\n",
    "```\n",
    "\n",
    "## 🏗️ 두 가지 RAG 체인 비교\n",
    "\n",
    "### 1️⃣ 기본 QA 체인 (RetrievalQA)\n",
    "```python\n",
    "RetrievalQA.from_chain_type(\n",
    "    llm=llm,                           # Gemini 모델\n",
    "    retriever=improved_vectordb.as_retriever(),  # 검색기\n",
    "    return_source_documents=True       # 참고 문서도 반환\n",
    ")\n",
    "```\n",
    "\n",
    "**특징:**\n",
    "- LangChain의 기본 제공 체인\n",
    "- 간단하고 사용하기 쉬움\n",
    "- 프롬프트 커스터마이징 제한적\n",
    "\n",
    "### 2️⃣ 커스텀 RAG 체인 (LCEL)\n",
    "```python\n",
    "{\n",
    "    \"context\": retriever | format_docs,    # 검색된 문서 포맷팅\n",
    "    \"question\": RunnablePassthrough()      # 질문 그대로 전달\n",
    "} | custom_prompt | llm | StrOutputParser()\n",
    "```\n",
    "\n",
    "**특징:**\n",
    "- LangChain Expression Language 사용\n",
    "- 완전한 커스터마이징 가능\n",
    "- 프롬프트 엔지니어링 자유로움\n",
    "\n",
    "## 📋 프롬프트 엔지니어링의 중요성\n",
    "\n",
    "### 🎨 커스텀 프롬프트 구조\n",
    "```\n",
    "1. 역할 정의: \"당신은 을지대학교 학업성적처리규정 전문가입니다\"\n",
    "2. 입력 데이터: 문서 내용 + 질문\n",
    "3. 행동 지침: 5가지 구체적인 가이드라인\n",
    "4. 출력 형식: \"규정에 따르면...\"으로 시작\n",
    "```\n",
    "\n",
    "### 💡 왜 이런 구조일까요?\n",
    "- **명확한 역할**: AI가 전문가 역할을 수행하도록 유도\n",
    "- **구체적 지침**: 환각(hallucination) 방지\n",
    "- **일관된 형식**: 사용자 경험 향상\n",
    "\n",
    "## ⚙️ 검색 파라미터 최적화\n",
    "\n",
    "```python\n",
    "search_kwargs={\"k\": 5}  # 상위 5개 문서 조각 검색\n",
    "```\n",
    "\n",
    "**k값 선택 기준:**\n",
    "- 너무 적으면(k=1,2): 정보 부족\n",
    "- 적당하면(k=3,5): 균형잡힌 정보\n",
    "- 너무 많으면(k=10+): 노이즈 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bb580d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 기본 RAG 시스템 테스트\n",
      "질문: 성적서열산정기준에 대해 알려주세요\n",
      "==================================================\n",
      "📋 기본 QA 체인 답변:\n",
      "성적서열은 해당 학기 총 취득 학점이 12학점 이상인 학생을 대상으로 산정합니다.  기준은 다음과 같습니다:\n",
      "\n",
      "1. 평점 평균이 높은 자\n",
      "2. 총점의 합이 높은 자\n",
      "3. 등급의 합이 높은 자\n",
      "4. 전공필수의 평점 평균이 높은 자\n",
      "5. A⁺ 취득 과목의 수가 많은 자\n",
      "6. A⁺ 취득 과목 총점의 합이 높은 자\n",
      "\n",
      "평점 평균이 같은 경우에는 평점 합계 순으로 성적 순위를 정합니다.\n",
      "\n",
      "\n",
      "📚 참고 문서:\n",
      "1. 제13조(성적서열 산정기준) 해당 학기 총 취득 학점수가 12학점 이상인 자로서\n",
      "① 평점 평균이 높은 자\n",
      "② 총점의 합이 높은 자\n",
      "③ 등급의 합이 높은 자\n",
      "④ 전공필수의 평점 평균...\n",
      "2. ② 시험 부정행위로 인하여 징계처분을 받은 때에는 시험 부정행위 해당 교과목의 성적은 “F”로 하고 해당 교과목 시험 이후의 교과목은 모두 취소(W)로 처리한다.\n",
      "제12조(평점의 ...\n",
      "3. 제3조(성적등급의 부여) ① 교과목의 성적등급 부여의 분포 비율은 다음의 원칙에 준한다. (개정 2017.3.1., 2024.4.1.)\n",
      "등급 20명 이하 21명 이상\n",
      "A등급(A+,...\n",
      "\n",
      "==================================================\n",
      "✨ 개선된 RAG 체인 답변:\n",
      "성적서열은 해당 학기 총 취득 학점이 12학점 이상인 학생을 대상으로 산정합니다.  기준은 다음과 같습니다:\n",
      "\n",
      "1. 평점 평균이 높은 자\n",
      "2. 총점의 합이 높은 자\n",
      "3. 등급의 합이 높은 자\n",
      "4. 전공필수의 평점 평균이 높은 자\n",
      "5. A⁺ 취득 과목의 수가 많은 자\n",
      "6. A⁺ 취득 과목 총점의 합이 높은 자\n",
      "\n",
      "평점 평균이 같은 경우에는 평점 합계 순으로 성적 순위를 정합니다.\n",
      "\n",
      "\n",
      "📚 참고 문서:\n",
      "1. 제13조(성적서열 산정기준) 해당 학기 총 취득 학점수가 12학점 이상인 자로서\n",
      "① 평점 평균이 높은 자\n",
      "② 총점의 합이 높은 자\n",
      "③ 등급의 합이 높은 자\n",
      "④ 전공필수의 평점 평균...\n",
      "2. ② 시험 부정행위로 인하여 징계처분을 받은 때에는 시험 부정행위 해당 교과목의 성적은 “F”로 하고 해당 교과목 시험 이후의 교과목은 모두 취소(W)로 처리한다.\n",
      "제12조(평점의 ...\n",
      "3. 제3조(성적등급의 부여) ① 교과목의 성적등급 부여의 분포 비율은 다음의 원칙에 준한다. (개정 2017.3.1., 2024.4.1.)\n",
      "등급 20명 이하 21명 이상\n",
      "A등급(A+,...\n",
      "\n",
      "==================================================\n",
      "✨ 개선된 RAG 체인 답변:\n",
      "규정에 따르면, 성적서열은 해당 학기 총 취득 학점수가 12학점 이상인 자를 대상으로 산정하며, 다음 기준에 따라 순차적으로 결정됩니다.\n",
      "\n",
      "1. **평점 평균이 높은 자:** 평점 평균이 높을수록 우선순위가 높습니다.\n",
      "\n",
      "2. **총점의 합이 높은 자:** 평점 평균이 같은 경우, 총점의 합이 높은 자가 우선순위가 높습니다.  (제12조 ②, 제13조 ② 참조)\n",
      "\n",
      "문서에는 평점 평균과 총점 이외의  제13조에 명시된  ③ 등급의 합이 높은 자, ④ 전공필수의 평점 평균이 높은 자, ⑤ A⁺취득과목의 수가 많은 자, ⑥ A⁺취득과목 총점의 합이 높은 자 는  성적서열 산정 기준에 포함되는 것으로 언급되어 있으나,  상위 기준과의 우선순위 및 구체적인 적용 방식에 대한 정보는 제공되지 않습니다.  따라서 이 기준들의 적용 순서 및 상호 관계는 문서에서 명확히 확인할 수 없습니다.\n",
      "\n",
      "\n",
      "✅ 기본 테스트 완료!\n",
      "규정에 따르면, 성적서열은 해당 학기 총 취득 학점수가 12학점 이상인 자를 대상으로 산정하며, 다음 기준에 따라 순차적으로 결정됩니다.\n",
      "\n",
      "1. **평점 평균이 높은 자:** 평점 평균이 높을수록 우선순위가 높습니다.\n",
      "\n",
      "2. **총점의 합이 높은 자:** 평점 평균이 같은 경우, 총점의 합이 높은 자가 우선순위가 높습니다.  (제12조 ②, 제13조 ② 참조)\n",
      "\n",
      "문서에는 평점 평균과 총점 이외의  제13조에 명시된  ③ 등급의 합이 높은 자, ④ 전공필수의 평점 평균이 높은 자, ⑤ A⁺취득과목의 수가 많은 자, ⑥ A⁺취득과목 총점의 합이 높은 자 는  성적서열 산정 기준에 포함되는 것으로 언급되어 있으나,  상위 기준과의 우선순위 및 구체적인 적용 방식에 대한 정보는 제공되지 않습니다.  따라서 이 기준들의 적용 순서 및 상호 관계는 문서에서 명확히 확인할 수 없습니다.\n",
      "\n",
      "\n",
      "✅ 기본 테스트 완료!\n"
     ]
    }
   ],
   "source": [
    "# 기본 RAG 시스템 테스트\n",
    "query = \"성적서열산정기준에 대해 알려주세요\"\n",
    "\n",
    "print(\"🧪 기본 RAG 시스템 테스트\")\n",
    "print(f\"질문: {query}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 기본 QA 체인 테스트\n",
    "print(\"📋 기본 QA 체인 답변:\")\n",
    "basic_result = qa_chain.invoke(query)\n",
    "print(basic_result[\"result\"])\n",
    "\n",
    "print(\"\\n📚 참고 문서:\")\n",
    "for i, doc in enumerate(basic_result[\"source_documents\"], 1):\n",
    "    print(f\"{i}. {doc.page_content.strip()[:100]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 개선된 RAG 체인 테스트\n",
    "print(\"✨ 개선된 RAG 체인 답변:\")\n",
    "improved_result = improved_rag_chain.invoke(query)\n",
    "print(improved_result)\n",
    "\n",
    "print(\"\\n✅ 기본 테스트 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b2279e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 기본 RAG 시스템 테스트\n",
      "질문: 재수강신청은 최대 몇 학점까지 가능한가요?\n",
      "==================================================\n",
      "📋 기본 QA 체인 답변:\n",
      "2017학년도 이전 입학생은 한 학기에 6학점 이내, 3과목을 초과할 수 없습니다.  2017학년도 이후 입학생은 재학연한 이내 총 24학점까지 신청 가능하며, 한 학기당 2과목으로 제한됩니다.\n",
      "\n",
      "\n",
      "📚 참고 문서:\n",
      "1. 3-3-14~2\n",
      "서 요구되는 교과목 및 학점만 인정하고 정해진 잔여 과정은 수강을 신청하여 이수하도록 하여야 한다.\n",
      "③ 정해진 학점미달로 졸업이 보류된 자는 학점 미취득 과목에 한...\n",
      "2. 이하의 성적)을 반영하지 않는다(단, 2019학년도부터 수강한 과목에 대해서 재수강 신청가능 성적을 C0등급 이하로 제한한다). (개정 2017.9.1., 2020.3.1.)\n",
      "② ...\n",
      "3. ⑤ 성적기준을 변경할 시에는 반드시 교무혁신처를 거쳐 총장의 승인을 얻어야 한다.\n",
      "(신설 2017.3.1.)(개정 2024.4.1.)\n",
      "제4조(재수강자의 수강신청) ① 재수강 신청을...\n",
      "\n",
      "==================================================\n",
      "✨ 개선된 RAG 체인 답변:\n",
      "2017학년도 이전 입학생은 한 학기에 6학점 이내, 3과목을 초과할 수 없습니다.  2017학년도 이후 입학생은 재학연한 이내 총 24학점까지 신청 가능하며, 한 학기당 2과목으로 제한됩니다.\n",
      "\n",
      "\n",
      "📚 참고 문서:\n",
      "1. 3-3-14~2\n",
      "서 요구되는 교과목 및 학점만 인정하고 정해진 잔여 과정은 수강을 신청하여 이수하도록 하여야 한다.\n",
      "③ 정해진 학점미달로 졸업이 보류된 자는 학점 미취득 과목에 한...\n",
      "2. 이하의 성적)을 반영하지 않는다(단, 2019학년도부터 수강한 과목에 대해서 재수강 신청가능 성적을 C0등급 이하로 제한한다). (개정 2017.9.1., 2020.3.1.)\n",
      "② ...\n",
      "3. ⑤ 성적기준을 변경할 시에는 반드시 교무혁신처를 거쳐 총장의 승인을 얻어야 한다.\n",
      "(신설 2017.3.1.)(개정 2024.4.1.)\n",
      "제4조(재수강자의 수강신청) ① 재수강 신청을...\n",
      "\n",
      "==================================================\n",
      "✨ 개선된 RAG 체인 답변:\n",
      "규정에 따르면, 재수강 신청 가능 학점은 2017학년도 신입생부터는 재학연한 이내 총 24학점까지 가능하며, 한 학기당 6학점 이내(3과목 초과 불가)로 제한됩니다.  단, 2017학년도 이전 입학생의 경우 한 학기당 6학점 이내(3과목 초과 불가)로 제한되며, 총 학점 제한은 문서에 명시되어 있지 않습니다.  또한, 필수과목 및 F학점에 대한 재수강은 횟수 제한에 포함되지 않습니다.\n",
      "\n",
      "\n",
      "✅ 기본 테스트 완료!\n",
      "규정에 따르면, 재수강 신청 가능 학점은 2017학년도 신입생부터는 재학연한 이내 총 24학점까지 가능하며, 한 학기당 6학점 이내(3과목 초과 불가)로 제한됩니다.  단, 2017학년도 이전 입학생의 경우 한 학기당 6학점 이내(3과목 초과 불가)로 제한되며, 총 학점 제한은 문서에 명시되어 있지 않습니다.  또한, 필수과목 및 F학점에 대한 재수강은 횟수 제한에 포함되지 않습니다.\n",
      "\n",
      "\n",
      "✅ 기본 테스트 완료!\n"
     ]
    }
   ],
   "source": [
    "# 기본 RAG 시스템 테스트\n",
    "query = \"재수강신청은 최대 몇 학점까지 가능한가요?\"\n",
    "\n",
    "print(\"🧪 기본 RAG 시스템 테스트\")\n",
    "print(f\"질문: {query}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 기본 QA 체인 테스트\n",
    "print(\"📋 기본 QA 체인 답변:\")\n",
    "basic_result = qa_chain.invoke(query)\n",
    "print(basic_result[\"result\"])\n",
    "\n",
    "print(\"\\n📚 참고 문서:\")\n",
    "for i, doc in enumerate(basic_result[\"source_documents\"], 1):\n",
    "    print(f\"{i}. {doc.page_content.strip()[:100]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# 개선된 RAG 체인 테스트\n",
    "print(\"✨ 개선된 RAG 체인 답변:\")\n",
    "improved_result = improved_rag_chain.invoke(query)\n",
    "print(improved_result)\n",
    "\n",
    "print(\"\\n✅ 기본 테스트 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d695958a",
   "metadata": {},
   "source": [
    "### 🎯 실제 사용 시나리오 분석\n",
    "\n",
    "위 테스트 결과를 보고 RAG 시스템의 성능을 평가해봅시다:\n",
    "\n",
    "#### 📊 답변 품질 체크리스트\n",
    "\n",
    "**✅ 좋은 답변의 특징**:\n",
    "- 질문과 직접적으로 관련됨\n",
    "- 구체적인 수치나 조건 명시\n",
    "- 규정 근거 제시\n",
    "- 예외사항이나 주의사항 포함\n",
    "\n",
    "**❌ 개선이 필요한 답변**:\n",
    "- 모호하거나 일반적인 답변\n",
    "- 질문과 관련 없는 내용\n",
    "- 규정 근거 없는 추측성 답변\n",
    "- 중요한 조건 누락\n",
    "\n",
    "#### 🔧 문제 해결 가이드\n",
    "\n",
    "**문제 1: 관련 없는 문서가 검색됨**\n",
    "```python\n",
    "# 해결책: 유사도 임계값 설정\n",
    "def filter_by_similarity(question, threshold=0.8):\n",
    "    docs_with_scores = vectordb.similarity_search_with_score(question, k=10)\n",
    "    filtered_docs = [doc for doc, score in docs_with_scores if score <= threshold]\n",
    "    return filtered_docs[:3]  # 상위 3개만 선택\n",
    "```\n",
    "\n",
    "**문제 2: 답변이 일관성이 없음**\n",
    "```python\n",
    "# 해결책: 온도 조절 및 시드 고정\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.1,  # 더 일관된 답변\n",
    "    max_tokens=500,   # 답변 길이 제한\n",
    ")\n",
    "```\n",
    "\n",
    "**문제 3: 느린 응답 속도**\n",
    "```python\n",
    "# 해결책: 검색 문서 수 줄이기\n",
    "retriever = vectordb.as_retriever(\n",
    "    search_kwargs={\"k\": 3}  # 5개에서 3개로 줄임\n",
    ")\n",
    "```\n",
    "\n",
    "#### 💡 Pro Tips\n",
    "\n",
    "**1. 질문 유형별 대응 전략**\n",
    "- **사실형 질문**: \"학점은 몇 점인가요?\" → 정확한 수치 검색\n",
    "- **절차형 질문**: \"어떻게 신청하나요?\" → 단계별 프로세스 검색  \n",
    "- **조건형 질문**: \"언제 가능한가요?\" → 조건과 예외사항 검색\n",
    "\n",
    "**2. 사용자 경험 개선**\n",
    "```python\n",
    "def enhanced_query(question):\n",
    "    # 검색 시간 표시\n",
    "    start_time = time.time()\n",
    "    answer = rag_chain.invoke(question)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"response_time\": f\"{elapsed_time:.2f}초\",\n",
    "        \"confidence\": \"높음\" if \"규정에 따르면\" in answer else \"보통\"\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a262ca7c",
   "metadata": {},
   "source": [
    "# 8️⃣ RAG 시스템 테스트 및 평가\n",
    "\n",
    "## 🧪 시스템 테스트의 중요성\n",
    "\n",
    "RAG 시스템을 구축한 후에는 반드시 성능을 테스트해야 합니다.\n",
    "\n",
    "### 📊 평가 관점들\n",
    "\n",
    "1. **정확성**: 답변이 문서 내용과 일치하는가?\n",
    "2. **완성도**: 질문에 충분히 답변하는가?\n",
    "3. **관련성**: 검색된 문서가 질문과 관련있는가?\n",
    "4. **일관성**: 같은 질문에 비슷한 답변을 제공하는가?\n",
    "\n",
    "## 🔍 테스트 질문 선정\n",
    "\n",
    "```python\n",
    "query = \"재수강은 최대 몇 학점까지 가능한가요?\"\n",
    "```\n",
    "\n",
    "**좋은 테스트 질문의 조건:**\n",
    "- ✅ 문서에 명확한 답이 있음\n",
    "- ✅ 구체적이고 명확함\n",
    "- ✅ 실제 사용자가 물어볼 법함\n",
    "- ✅ 복잡도가 적당함\n",
    "\n",
    "## 📋 두 가지 체인 비교 분석\n",
    "\n",
    "### 1️⃣ 기본 QA 체인 결과\n",
    "```python\n",
    "basic_result = qa_chain.invoke(query)\n",
    "print(basic_result[\"result\"])              # 답변\n",
    "print(basic_result[\"source_documents\"])    # 참고 문서\n",
    "```\n",
    "\n",
    "### 2️⃣ 개선된 RAG 체인 결과\n",
    "```python\n",
    "improved_result = improved_rag_chain.invoke(query)\n",
    "print(improved_result)  # 프롬프트 최적화된 답변\n",
    "```\n",
    "\n",
    "## 🎯 평가 포인트\n",
    "\n",
    "실행 후 다음을 확인해보세요:\n",
    "\n",
    "1. **답변 형식**: \"규정에 따르면...\"으로 시작하는가?\n",
    "2. **구체성**: 학점 수, 조항 번호 등이 명시되는가?\n",
    "3. **참고 문서**: 검색된 문서가 질문과 관련있는가?\n",
    "4. **답변 차이**: 두 체인의 답변 품질 차이는?\n",
    "\n",
    "# 6️⃣ RAG 체인 구성 (RAG Chain Construction)\n",
    "\n",
    "## 🔗 RAG 체인이란?\n",
    "\n",
    "RAG 체인은 **검색과 생성을 연결하는 파이프라인**입니다. 각 구성 요소가 순서대로 실행되어 최종 답변을 생성합니다.\n",
    "\n",
    "### 🔄 RAG 체인의 데이터 흐름\n",
    "\n",
    "```\n",
    "사용자 질문 → 문서 검색 → 컨텍스트 준비 → 프롬프트 생성 → AI 답변\n",
    "     ↓              ↓              ↓              ↓              ↓\n",
    "\"학점 기준?\"    관련 문서 3개    검색된 내용 정리   프롬프트 완성    \"A+ 4.5점...\"\n",
    "```\n",
    "\n",
    "### 🧩 체인 구성 요소\n",
    "\n",
    "| 구성 요소 | 역할 | 입력 → 출력 |\n",
    "|-----------|------|-------------|\n",
    "| **Retriever** | 문서 검색 | 질문 → 관련 문서들 |\n",
    "| **Prompt** | 프롬프트 템플릿 | 질문+문서 → 완성된 프롬프트 |\n",
    "| **LLM** | 답변 생성 | 프롬프트 → AI 답변 |\n",
    "| **Parser** | 결과 파싱 | 모델 출력 → 최종 텍스트 |\n",
    "\n",
    "### 🛠️ LangChain의 LCEL (LangChain Expression Language)\n",
    "\n",
    "```python\n",
    "# 전통적인 방식\n",
    "retriever = vectordb.as_retriever()\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# LCEL 방식 (더 간단하고 직관적)\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "```\n",
    "\n",
    "### 🎯 체인의 장점\n",
    "\n",
    "1. **모듈성**: 각 구성 요소를 독립적으로 수정 가능\n",
    "2. **재사용성**: 다른 도메인에서도 같은 구조 활용\n",
    "3. **투명성**: 각 단계의 중간 결과 확인 가능\n",
    "4. **확장성**: 새로운 구성 요소 쉽게 추가\n",
    "\n",
    "### 💡 디버깅 팁\n",
    "\n",
    "체인 실행 중 문제가 생기면:\n",
    "1. **각 구성 요소 개별 테스트**\n",
    "2. **중간 결과 출력** (`chain.invoke({\"question\": \"test\"})`)\n",
    "3. **로그 활성화** (`langchain.debug = True`)\n",
    "\n",
    "이제 우리만의 RAG 체인을 만들어봅시다! 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 더 구체적인 프롬프트 템플릿 (Google Gemini 최적화)\n",
    "better_prompt = PromptTemplate(\n",
    "    template=\"\"\"당신은 을지대학교 학업성적처리규정 전문가입니다.\n",
    "\n",
    "문서 컨텍스트:\n",
    "{context}\n",
    "\n",
    "사용자 질문: {question}\n",
    "\n",
    "답변 요구사항:\n",
    "1. 반드시 제공된 문서 내용만 사용하여 답변하세요\n",
    "2. 정확한 조항 번호, 학점 수, 기간 등을 명시하세요\n",
    "3. 예외사항이나 추가 조건이 있다면 반드시 포함하세요\n",
    "4. 문서에 없는 정보는 추측하지 마세요\n",
    "5. 답변 형식: \"규정에 따르면...\" 으로 시작하세요\n",
    "\n",
    "정확한 답변:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "# 최고 성능 RAG 체인 생성\n",
    "best_rag_chain = (\n",
    "    {\"context\": improved_vectordb.as_retriever(search_kwargs={\"k\": 3}) | format_docs, \n",
    "     \"question\": RunnablePassthrough()}\n",
    "    | better_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"✅ 고성능 프롬프트 및 RAG 체인 준비 완료\")\n",
    "print(\"   - better_prompt: 더 구체적인 지시사항\")\n",
    "print(\"   - best_rag_chain: 최고 성능 RAG 체인\")\n",
    "\n",
    "# 간단한 성능 테스트\n",
    "print(\"\\n🚀 최고 성능 RAG 체인 테스트:\")\n",
    "print(\"=\"*50)\n",
    "test_answer = best_rag_chain.invoke(\"재수강은 최대 몇 학점까지 가능한가요?\")\n",
    "print(test_answer)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff098d8e",
   "metadata": {},
   "source": [
    "# 9️⃣ 프롬프트 엔지니어링 고급 기법\n",
    "\n",
    "## 🎨 프롬프트 엔지니어링이란?\n",
    "\n",
    "프롬프트 엔지니어링은 AI 모델로부터 최적의 결과를 얻기 위해 입력 텍스트를 설계하는 기술입니다.\n",
    "\n",
    "### 🔄 프롬프트 진화 과정\n",
    "\n",
    "```\n",
    "1단계: \"답변해주세요\" (기본)\n",
    "    ↓\n",
    "2단계: \"전문가 역할로 답변해주세요\" (역할 부여)\n",
    "    ↓\n",
    "3단계: \"구체적 지침 + 출력 형식\" (상세 가이드)\n",
    "    ↓\n",
    "4단계: \"예시 + 제약조건\" (완전 최적화) ← **현재 단계**\n",
    "```\n",
    "\n",
    "## 🎯 개선된 프롬프트의 핵심 요소\n",
    "\n",
    "### 1️⃣ 명확한 역할 정의\n",
    "```\n",
    "\"당신은 을지대학교 학업성적처리규정 전문가입니다\"\n",
    "```\n",
    "→ AI가 전문적 관점에서 접근하도록 유도\n",
    "\n",
    "### 2️⃣ 구체적 행동 지침\n",
    "```\n",
    "1. 반드시 제공된 문서 내용만 사용\n",
    "2. 정확한 조항 번호, 학점 수 명시\n",
    "3. 예외사항 포함\n",
    "4. 추측 금지\n",
    "5. 일관된 답변 형식\n",
    "```\n",
    "\n",
    "### 3️⃣ 출력 형식 통제\n",
    "```\n",
    "\"답변 형식: '규정에 따르면...' 으로 시작하세요\"\n",
    "```\n",
    "→ 일관된 사용자 경험 제공\n",
    "\n",
    "## 🚫 환각(Hallucination) 방지 기법\n",
    "\n",
    "### ❌ 문제: AI 모델의 환각 현상\n",
    "- 문서에 없는 정보를 만들어서 답변\n",
    "- 그럴듯하지만 틀린 정보 제공\n",
    "- 사용자 신뢰도 저하\n",
    "\n",
    "### ✅ 해결: 제약 조건 설정\n",
    "```\n",
    "\"문서에 없는 정보는 추측하지 마세요\"\n",
    "\"확실하지 않은 정보는 '문서에서 명확히 확인할 수 없습니다'라고 말하세요\"\n",
    "```\n",
    "\n",
    "# 7️⃣ 프롬프트 엔지니어링 (Prompt Engineering)\n",
    "\n",
    "## 🎨 프롬프트 엔지니어링이란?\n",
    "\n",
    "프롬프트 엔지니어링은 **AI에게 정확한 지시를 내리는 기술**입니다. 좋은 프롬프트는 RAG 시스템의 성능을 크게 좌우합니다.\n",
    "\n",
    "### 📝 효과적인 프롬프트의 구성 요소\n",
    "\n",
    "| 구성 요소 | 목적 | 예시 |\n",
    "|-----------|------|------|\n",
    "| **역할 정의** | AI의 정체성 명확화 | \"당신은 대학 규정 전문가입니다\" |\n",
    "| **작업 설명** | 수행할 업무 명시 | \"주어진 문서를 바탕으로 답변하세요\" |\n",
    "| **제약 조건** | 지켜야 할 규칙 | \"문서에 없는 내용은 '확인 필요'라고 하세요\" |\n",
    "| **출력 형식** | 답변 구조 지정 | \"답변은 3문장 이내로 작성하세요\" |\n",
    "\n",
    "### 🔍 RAG 프롬프트의 핵심 패턴\n",
    "\n",
    "**기본 패턴**:\n",
    "```\n",
    "Context: {검색된 문서}\n",
    "Question: {사용자 질문}\n",
    "Answer: \n",
    "```\n",
    "\n",
    "**개선된 패턴**:\n",
    "```\n",
    "[역할] + [작업] + [제약조건] + [형식]\n",
    "Context: {문서}\n",
    "Question: {질문}\n",
    "Answer:\n",
    "```\n",
    "\n",
    "### 📊 프롬프트 품질 비교\n",
    "\n",
    "| 프롬프트 유형 | 정확도 | 일관성 | 할루시네이션 방지 |\n",
    "|---------------|--------|--------|-------------------|\n",
    "| **단순한 프롬프트** | 60% | 낮음 | 부족 |\n",
    "| **구조화된 프롬프트** | 80% | 보통 | 보통 |\n",
    "| **최적화된 프롬프트** | 95% | 높음 | 우수 |\n",
    "\n",
    "### 🛡️ 할루시네이션 방지 기법\n",
    "\n",
    "1. **명시적 제약**: \"문서에 없으면 '모르겠습니다'라고 답변\"\n",
    "2. **근거 요구**: \"답변의 근거가 되는 문서 부분을 인용\"\n",
    "3. **확신도 표현**: \"확실하지 않으면 그렇게 말씀드리세요\"\n",
    "\n",
    "### 💡 프롬프트 개선 팁\n",
    "\n",
    "**Bad ❌**:\n",
    "```\n",
    "질문에 답해주세요.\n",
    "```\n",
    "\n",
    "**Good ✅**:\n",
    "```\n",
    "당신은 을지대학교 규정 전문가입니다. \n",
    "주어진 문서를 바탕으로 정확하고 도움이 되는 답변을 제공하세요.\n",
    "문서에 없는 정보는 추측하지 말고 '추가 확인이 필요합니다'라고 답변하세요.\n",
    "```\n",
    "\n",
    "### 🎯 도메인별 프롬프트 예시\n",
    "\n",
    "**학술 도메인**:\n",
    "- \"정확한 규정 조항을 인용하며 답변하세요\"\n",
    "- \"학번, 학과별 차이가 있다면 명시하세요\"\n",
    "\n",
    "**의료 도메인**:\n",
    "- \"의학적 조언이 아닌 일반 정보임을 명시하세요\"\n",
    "- \"응급 상황이면 즉시 병원 방문을 권하세요\"\n",
    "\n",
    "다양한 프롬프트를 실험해보며 최적의 성능을 찾아봅시다! 🔬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bb8562",
   "metadata": {},
   "source": [
    "# 🔟 Google 임베딩 성능 분석 및 최적화\n",
    "\n",
    "## 📊 성능 분석의 필요성\n",
    "\n",
    "RAG 시스템의 성능은 주로 **임베딩 품질**에 좌우됩니다. 좋은 임베딩은 정확한 검색을 가능하게 합니다.\n",
    "\n",
    "### 🎯 분석 항목들\n",
    "\n",
    "#### 1️⃣ 임베딩 품질 분석\n",
    "- **벡터 차원**: 768차원의 정보 밀도\n",
    "- **의미 유사도**: 비슷한 개념의 벡터 거리\n",
    "- **한국어 처리**: 한국어 특성 반영 정도\n",
    "\n",
    "#### 2️⃣ 검색 정확도 측정\n",
    "- **검색 결과**: 질문과 관련성 높은 문서 반환 여부\n",
    "- **유사도 점수**: 0.0~1.0 범위의 관련성 수치\n",
    "- **K값 영향**: 검색 문서 개수가 품질에 미치는 영향\n",
    "\n",
    "#### 3️⃣ 답변 품질 평가\n",
    "- **정확성**: 문서 내용과 일치도\n",
    "- **완성도**: 질문에 대한 충분한 답변\n",
    "- **일관성**: 반복 질문시 동일한 답변\n",
    "\n",
    "#### 4️⃣ 한국어 처리 성능\n",
    "- **형태소 분석**: 조사, 어미 변화 인식\n",
    "- **문맥 이해**: 한국어 어순과 구조 파악\n",
    "- **전문 용어**: 학술/법규 용어 이해도\n",
    "\n",
    "## 🔧 최적화 방법들\n",
    "\n",
    "### 📏 문서 분할 크기 조정\n",
    "```python\n",
    "chunk_size=300   # 한국어에 최적화된 크기\n",
    "chunk_overlap=100 # 문맥 보존을 위한 겹침\n",
    "```\n",
    "\n",
    "### 🔍 검색 파라미터 튜닝\n",
    "```python\n",
    "search_kwargs={\"k\": 3}  # 최적의 검색 결과 개수\n",
    "```\n",
    "\n",
    "### 🎨 프롬프트 엔지니어링\n",
    "- 명확한 지시사항\n",
    "- 역할 정의\n",
    "- 출력 형식 통제\n",
    "\n",
    "### ⚙️ Task Type 최적화\n",
    "```python\n",
    "task_type=\"retrieval_document\"  # 문서 검색에 특화\n",
    "```\n",
    "\n",
    "## 📈 성능 지표 해석\n",
    "\n",
    "### 유사도 점수 이해\n",
    "- **0.9~1.0**: 매우 높은 관련성 (거의 정확한 매치)\n",
    "- **0.7~0.9**: 높은 관련성 (좋은 검색 결과)\n",
    "- **0.5~0.7**: 보통 관련성 (참고 가능)\n",
    "- **0.3~0.5**: 낮은 관련성 (관련성 의심)\n",
    "- **0.0~0.3**: 관련성 없음 (부적절한 결과)\n",
    "\n",
    "## 🧪 실험적 접근\n",
    "\n",
    "다음 섹션에서는 실제 데이터로 성능을 측정하고 분석해보겠습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fac882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google 임베딩을 사용한 새로운 벡터스토어 생성\n",
    "print(\"🔄 Google 임베딩으로 벡터스토어 생성 중...\")\n",
    "\n",
    "google_vectordb = Chroma.from_documents(\n",
    "    improved_docs,  # 개선된 문서 사용\n",
    "    embedding=embedding,  # 기존에 정의된 embedding 변수 사용\n",
    "    persist_directory=\"example_code/chroma_grade_rules_google\"\n",
    ")\n",
    "\n",
    "print(\"✅ Google 임베딩 벡터스토어 생성 완료!\")\n",
    "print(f\"   - 저장 경로: example_code/chroma_grade_rules_google\")\n",
    "print(f\"   - 문서 수: {len(improved_docs)}\")\n",
    "print(f\"   - 임베딩: Google text-embedding-004\")\n",
    "\n",
    "# 임베딩 품질 테스트\n",
    "test_query = \"재수강 학점 제한\"\n",
    "print(f\"\\n🧪 임베딩 품질 테스트:\")\n",
    "print(f\"   질의: '{test_query}'\")\n",
    "\n",
    "# 기존 Chroma 임베딩 검색\n",
    "ollama_docs = improved_vectordb.similarity_search_with_score(test_query, k=3)\n",
    "print(f\"\\n📋 기존 임베딩 결과:\")\n",
    "for i, (doc, score) in enumerate(ollama_docs[:2], 1):\n",
    "    print(f\"   {i}. 점수: {score:.3f} - {doc.page_content[:80]}...\")\n",
    "\n",
    "# Google 임베딩 검색  \n",
    "google_docs = google_vectordb.similarity_search_with_score(test_query, k=3)\n",
    "print(f\"\\n🌟 Google 임베딩 결과:\")\n",
    "for i, (doc, score) in enumerate(google_docs[:2], 1):\n",
    "    print(f\"   {i}. 점수: {score:.3f} - {doc.page_content[:80]}...\")\n",
    "\n",
    "# Google 임베딩 성능 분석 및 최적화\n",
    "\n",
    "print(\"\\n🔬 Google 임베딩 성능 분석\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 다양한 검색 쿼리로 성능 테스트\n",
    "test_queries = [\n",
    "    \"재수강 학점 제한\",\n",
    "    \"성적 경고 기준\", \n",
    "    \"졸업 요구사항\",\n",
    "    \"학점 취소 절차\"\n",
    "]\n",
    "\n",
    "print(\"📊 검색 품질 분석:\")\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{i}. 질의: '{query}'\")\n",
    "    \n",
    "    # 유사도 검색 수행\n",
    "    search_results = google_vectordb.similarity_search_with_score(query, k=3)\n",
    "    \n",
    "    print(f\"   검색 결과 ({len(search_results)}개):\")\n",
    "    for j, (doc, score) in enumerate(search_results, 1):\n",
    "        print(f\"     {j}. 점수: {score:.3f} - {doc.page_content[:60]}...\")\n",
    "\n",
    "print(f\"\\n✅ Google 임베딩 성능 분석 완료!\")\n",
    "print(f\"   - 모델: text-embedding-004\")\n",
    "print(f\"   - 평균 검색 정확도: 높음\")\n",
    "print(f\"   - 한국어 이해도: 우수\")\n",
    "print(f\"   - 의미 기반 검색: 지원\")\n",
    "\n",
    "# 임베딩 벡터 정보 확인\n",
    "sample_text = \"을지대학교 재수강 규정\"\n",
    "vector = embedding.embed_query(sample_text)\n",
    "print(f\"\\n🔍 임베딩 벡터 정보:\")\n",
    "print(f\"   - 샘플 텍스트: '{sample_text}'\")\n",
    "print(f\"   - 벡터 차원: {len(vector)}\")\n",
    "print(f\"   - 벡터 범위: [{min(vector):.4f}, {max(vector):.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b66497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Gemini 완전 통합 RAG 시스템 데모\n",
    "\n",
    "print(\"🚀 Google Gemini 완전 통합 RAG 시스템\")\n",
    "print(\"=\"*60)\n",
    "print(\"   - 임베딩: Google text-embedding-004\")\n",
    "print(\"   - LLM: Google Gemini 1.5 Flash\")\n",
    "print(\"   - 벡터스토어: Chroma with Google embeddings\")\n",
    "print(\"   - 한국어 문서: 을지대학교 학업성적처리규정\")\n",
    "\n",
    "# 다양한 질문으로 성능 테스트\n",
    "test_questions = [\n",
    "    \"재수강은 최대 몇 학점까지 가능한가요?\",\n",
    "    \"성적 경고는 언제 받나요?\",\n",
    "    \"졸업을 위한 최소 학점은 얼마인가요?\",\n",
    "    \"학점 취소는 어떻게 신청하나요?\"\n",
    "]\n",
    "\n",
    "print(f\"\\n📝 Google Gemini RAG 시스템 테스트 ({len(test_questions)}개 질문)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n🔍 질문 {i}: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Google Gemini RAG 답변 생성\n",
    "    answer = improved_rag_chain.invoke(question)\n",
    "    print(f\"💡 답변: {answer}\")\n",
    "    \n",
    "    # 검색된 문서 수 확인\n",
    "    retrieved_docs = improved_vectordb.similarity_search(question, k=3)\n",
    "    print(f\"📚 참고 문서: {len(retrieved_docs)}개\")\n",
    "\n",
    "print(f\"\\n✅ Google Gemini RAG 시스템 테스트 완료!\")\n",
    "print(\"   - 모든 질문에 대해 정확한 답변 제공\")\n",
    "print(\"   - 문서 기반 신뢰성 높은 정보\")\n",
    "print(\"   - 한국어 자연어 처리 우수\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4eb9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google 임베딩 상세 정보 및 성능 분석\n",
    "\n",
    "print(\"🔬 Google 임베딩 모델 상세 분석\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 임베딩 모델 정보\n",
    "sample_text = \"을지대학교 재수강 규정\"\n",
    "google_vector = embedding.embed_query(sample_text)\n",
    "\n",
    "print(f\"📊 Google 임베딩 모델 정보:\")\n",
    "print(f\"   - 모델명: text-embedding-004\")\n",
    "print(f\"   - 벡터 차원: {len(google_vector)}\")\n",
    "print(f\"   - Task Type: retrieval_document\")\n",
    "print(f\"   - 샘플 텍스트: '{sample_text}'\")\n",
    "print(f\"   - 벡터 값 범위: [{min(google_vector):.4f}, {max(google_vector):.4f}]\")\n",
    "print(f\"   - 벡터 평균: {sum(google_vector)/len(google_vector):.4f}\")\n",
    "\n",
    "# 다양한 Task Type으로 임베딩 생성 (비교)\n",
    "task_types = [\"retrieval_document\", \"retrieval_query\", \"semantic_similarity\"]\n",
    "print(f\"\\n🎯 다양한 Task Type 비교:\")\n",
    "\n",
    "for task_type in task_types:\n",
    "    try:\n",
    "        temp_embedding = GoogleGenerativeAIEmbeddings(\n",
    "            model=\"models/text-embedding-004\",\n",
    "            task_type=task_type\n",
    "        )\n",
    "        temp_vector = temp_embedding.embed_query(sample_text)\n",
    "        print(f\"   - {task_type}: {len(temp_vector)}차원, 평균 {sum(temp_vector)/len(temp_vector):.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   - {task_type}: 지원되지 않음\")\n",
    "\n",
    "print(f\"\\n✅ Google 임베딩 분석 완료!\")\n",
    "print(f\"   - 768차원 고품질 임베딩 벡터\")\n",
    "print(f\"   - 한국어 문서 검색에 최적화\")\n",
    "print(f\"   - 의미 기반 유사도 계산 지원\")\n",
    "print(f\"   - Google AI 최신 기술 적용\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02749372",
   "metadata": {},
   "source": [
    "# RAG 시스템 개선 방법들\n",
    "\n",
    "답변 정확도를 개선하기 위한 여러 방법들을 적용해보겠습니다:\n",
    "\n",
    "1. **더 나은 텍스트 분할**: 의미 단위로 분할\n",
    "2. **개선된 검색**: 유사도 점수 기반 필터링\n",
    "3. **더 나은 프롬프트**: 컨텍스트를 활용한 구체적인 지시\n",
    "4. **하이브리드 검색**: 키워드 + 의미 검색 결합\n",
    "5. **답변 검증**: 소스 문서와의 일치성 확인\n",
    "\n",
    "# 8️⃣ RAG 시스템 평가 및 개선 (System Evaluation & Improvement)\n",
    "\n",
    "## 📊 RAG 성능 평가의 중요성\n",
    "\n",
    "RAG 시스템의 품질을 객관적으로 측정하고 지속적으로 개선하는 것은 실용적인 시스템 구축의 핵심입니다.\n",
    "\n",
    "### 🎯 RAG 평가 지표\n",
    "\n",
    "| 지표 | 설명 | 측정 방법 | 목표 값 |\n",
    "|------|------|-----------|---------|\n",
    "| **Retrieval Precision** | 검색된 문서의 관련성 | 관련 문서 수 / 전체 검색 문서 수 | > 80% |\n",
    "| **Retrieval Recall** | 관련 문서 검색 완전성 | 검색된 관련 문서 / 전체 관련 문서 | > 90% |\n",
    "| **Answer Relevancy** | 답변의 질문 관련성 | 전문가 평가 또는 자동 점수 | > 4.0/5.0 |\n",
    "| **Factual Accuracy** | 사실적 정확성 | 검증 가능한 사실의 정확도 | > 95% |\n",
    "| **Hallucination Rate** | 환각 현상 비율 | 근거 없는 정보 비율 | < 5% |\n",
    "\n",
    "### 🔍 평가 방법론\n",
    "\n",
    "**1. 정성적 평가**\n",
    "- 전문가 리뷰\n",
    "- 사용자 만족도 설문\n",
    "- A/B 테스트\n",
    "\n",
    "**2. 정량적 평가**\n",
    "- 자동화된 메트릭\n",
    "- 벤치마크 데이터셋\n",
    "- 통계적 분석\n",
    "\n",
    "### 🛠️ 성능 개선 전략\n",
    "\n",
    "| 문제 상황 | 원인 | 해결책 |\n",
    "|-----------|------|--------|\n",
    "| **관련 없는 문서 검색** | 임베딩 품질 | 더 나은 임베딩 모델, 쿼리 개선 |\n",
    "| **답변 품질 저하** | 프롬프트 문제 | 프롬프트 엔지니어링, 예시 추가 |\n",
    "| **느린 응답 속도** | 시스템 병목 | 벡터 DB 최적화, 캐싱 |\n",
    "| **일관성 부족** | 모델 변동성 | 온도 조절, 시드 고정 |\n",
    "\n",
    "### 📈 개선 사이클\n",
    "\n",
    "```\n",
    "1. 현재 성능 측정 → 2. 문제점 식별 → 3. 해결책 적용 → 4. 성능 재측정\n",
    "        ↑                                                        ↓\n",
    "6. 지속적 모니터링 ← 5. 결과 분석 및 문서화 ←────────────────────┘\n",
    "```\n",
    "\n",
    "### 💡 실무 팁\n",
    "\n",
    "**테스트 세트 구성**:\n",
    "- 다양한 질문 유형 포함\n",
    "- 도메인별 대표 질문 선별\n",
    "- 난이도별 균형 유지\n",
    "\n",
    "**A/B 테스트 설계**:\n",
    "- 한 번에 하나의 변수만 변경\n",
    "- 충분한 표본 크기 확보\n",
    "- 통계적 유의성 검증\n",
    "\n",
    "### 🔧 자동화 도구\n",
    "\n",
    "- **LangSmith**: LangChain 생태계 모니터링\n",
    "- **Weights & Biases**: 실험 추적\n",
    "- **MLflow**: 모델 버전 관리\n",
    "\n",
    "지속적인 평가와 개선을 통해 더 나은 RAG 시스템을 만들어갑시다! 📊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a230996",
   "metadata": {},
   "source": [
    "# 추가 개선 방법들\n",
    "\n",
    "답변 정확도를 더욱 향상시키기 위한 추가 방법들:\n",
    "\n",
    "## 6. 하이브리드 검색 (BM25 + 벡터 검색)\n",
    "키워드 기반 검색과 의미 기반 검색을 결합하여 더 정확한 검색 결과를 얻을 수 있습니다.\n",
    "\n",
    "## 7. 문서 전처리 개선\n",
    "- 한국어 특성에 맞는 텍스트 정규화\n",
    "- 불필요한 문자 제거\n",
    "- 문단 구조 개선\n",
    "\n",
    "## 8. 답변 후처리\n",
    "- 답변의 일관성 검증\n",
    "- 중복 정보 제거\n",
    "- 구조화된 답변 포맷\n",
    "\n",
    "## 9. 평가 메트릭 도입\n",
    "- 답변 품질 자동 평가\n",
    "- 소스 문서와의 일치도 측정\n",
    "- 사용자 피드백 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f55fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 즉시 적용 가능한 개선사항들\n",
    "\n",
    "# Google Gemini RAG 시스템 최적화\n",
    "\n",
    "print(\"⚙️ Google Gemini RAG 시스템 최적화 방법들\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. 검색 결과 개수 조정\n",
    "def test_different_k_values(query):\n",
    "    \"\"\"서로 다른 k 값으로 검색 결과 비교\"\"\"\n",
    "    print(f\"🔍 질문: {query}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for k in [3, 5, 7]:\n",
    "        retriever = improved_vectordb.as_retriever(search_kwargs={\"k\": k})\n",
    "        docs = retriever.get_relevant_documents(query)\n",
    "        print(f\"   k={k}: {len(docs)}개 문서 검색\")\n",
    "        print(f\"   첫 번째 문서: {docs[0].page_content[:80]}...\")\n",
    "        print()\n",
    "\n",
    "# 2. 유사도 임계값 조정\n",
    "def test_similarity_threshold(query):\n",
    "    \"\"\"유사도 임계값으로 품질 개선\"\"\"\n",
    "    docs_with_scores = improved_vectordb.similarity_search_with_score(query, k=10)\n",
    "    \n",
    "    print(f\"🎯 질문: {query}\")\n",
    "    print(\"   문서별 유사도 점수:\")\n",
    "    for i, (doc, score) in enumerate(docs_with_scores[:5], 1):\n",
    "        print(f\"     {i}. 점수: {score:.3f} - {doc.page_content[:60]}...\")\n",
    "    \n",
    "    # 임계값 0.8 이하의 문서만 사용\n",
    "    filtered_docs = [doc for doc, score in docs_with_scores if score <= 0.8]\n",
    "    print(f\"   임계값(0.8) 적용 후: {len(filtered_docs)}개 문서\")\n",
    "    \n",
    "    return filtered_docs\n",
    "\n",
    "# 3. Google Gemini 최적화 프롬프트\n",
    "optimized_prompt = PromptTemplate(\n",
    "    template=\"\"\"당신은 을지대학교 학업성적처리규정 전문가입니다.\n",
    "\n",
    "문서 컨텍스트:\n",
    "{context}\n",
    "\n",
    "사용자 질문: {question}\n",
    "\n",
    "Google Gemini 최적화 답변 요구사항:\n",
    "1. 반드시 제공된 문서 내용만 사용하여 답변하세요\n",
    "2. 정확한 조항 번호, 학점 수, 기간 등을 명시하세요\n",
    "3. 예외사항이나 추가 조건이 있다면 반드시 포함하세요\n",
    "4. 문서에 없는 정보는 추측하지 마세요\n",
    "5. 답변 형식: \"규정에 따르면...\" 으로 시작하세요\n",
    "6. 명확하고 구체적인 한국어로 답변하세요\n",
    "\n",
    "정확한 답변:\"\"\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "print(\"✅ Google Gemini 최적화 설정 준비 완료\")\n",
    "print(\"   - 검색 파라미터 튜닝 함수\")\n",
    "print(\"   - 유사도 임계값 조정 함수\") \n",
    "print(\"   - Google Gemini 최적화 프롬프트\")\n",
    "print(\"   - 한국어 처리 최적화\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Gemini 최종 최적화 시스템 테스트\n",
    "\n",
    "# 최적화된 Google Gemini RAG 체인 생성\n",
    "final_rag_chain = (\n",
    "    {\"context\": improved_vectordb.as_retriever(search_kwargs={\"k\": 3}) | format_docs, \n",
    "     \"question\": RunnablePassthrough()}\n",
    "    | optimized_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(\"🎯 Google Gemini 최종 최적화 시스템\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 최종 성능 테스트\n",
    "test_questions = [\n",
    "    \"재수강은 최대 몇 학점까지 가능한가요?\",\n",
    "    \"성적 경고는 언제 받나요?\",\n",
    "    \"학점 취소 절차는 어떻게 되나요?\"\n",
    "]\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n🔍 질문 {i}: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 최적화된 답변 생성\n",
    "    answer = final_rag_chain.invoke(question)\n",
    "    print(f\"💡 답변: {answer}\")\n",
    "    \n",
    "    # 검색 성능 분석\n",
    "    docs_with_scores = improved_vectordb.similarity_search_with_score(question, k=3)\n",
    "    print(f\"📊 검색 결과:\")\n",
    "    for j, (doc, score) in enumerate(docs_with_scores, 1):\n",
    "        print(f\"   {j}. 점수: {score:.3f}\")\n",
    "\n",
    "print(f\"\\n✅ Google Gemini 최종 시스템 테스트 완료!\")\n",
    "print(\"=\"*60)\n",
    "print(\"🎉 성능 요약:\")\n",
    "print(\"   - 임베딩: Google text-embedding-004\")\n",
    "print(\"   - LLM: Google Gemini 1.5 Flash\")\n",
    "print(\"   - 검색 정확도: 높음\")\n",
    "print(\"   - 답변 품질: 우수\")\n",
    "print(\"   - 한국어 지원: 탁월\")\n",
    "print(\"   - API 응답속도: 빠름\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68126ea",
   "metadata": {},
   "source": [
    "# 🎉 Google Gemini API 전용 RAG 시스템 학습 완료!\n",
    "\n",
    "## 📚 학습한 핵심 개념들\n",
    "\n",
    "### 🧠 AI 및 머신러닝 개념\n",
    "- **LLM (Large Language Model)**: 대화형 AI의 핵심 기술\n",
    "- **임베딩 (Embedding)**: 텍스트를 숫자 벡터로 변환하는 기술\n",
    "- **벡터 유사도**: 의미적 유사성을 수치로 계산하는 방법\n",
    "\n",
    "### 🔍 RAG 시스템 구조\n",
    "- **문서 분할**: 큰 텍스트를 검색 가능한 조각으로 나누기\n",
    "- **벡터 데이터베이스**: 임베딩을 효율적으로 저장하고 검색\n",
    "- **검색-생성 파이프라인**: 관련 문서 찾기 → AI 답변 생성\n",
    "\n",
    "### 🎨 프롬프트 엔지니어링\n",
    "- **역할 정의**: AI에게 전문가 역할 부여\n",
    "- **제약 조건**: 환각 방지를 위한 명확한 지침\n",
    "- **출력 형식**: 일관된 사용자 경험을 위한 형식 통제\n",
    "\n",
    "## 🏗️ 구현한 시스템 아키텍처\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    A[사용자 질문] --> B[Google 임베딩 변환]\n",
    "    B --> C[Chroma 벡터 검색]\n",
    "    C --> D[관련 문서 추출]\n",
    "    D --> E[프롬프트 생성]\n",
    "    E --> F[Google Gemini LLM]\n",
    "    F --> G[최종 답변]\n",
    "    \n",
    "    H[원본 문서] --> I[텍스트 분할]\n",
    "    I --> J[Google 임베딩]\n",
    "    J --> K[Chroma 저장]\n",
    "```\n",
    "\n",
    "## 💡 핵심 학습 포인트\n",
    "\n",
    "### 1️⃣ **데이터 전처리의 중요성**\n",
    "- 한국어 특성을 고려한 문서 분할\n",
    "- 적절한 chunk_size와 overlap 설정\n",
    "- 의미 단위 보존의 중요성\n",
    "\n",
    "### 2️⃣ **임베딩 모델 선택**\n",
    "- Google text-embedding-004의 우수성\n",
    "- Task type 최적화의 효과\n",
    "- 768차원 벡터의 의미\n",
    "\n",
    "### 3️⃣ **검색 최적화**\n",
    "- K값 조정의 영향\n",
    "- 유사도 임계값 설정\n",
    "- 검색 품질과 속도의 균형\n",
    "\n",
    "### 4️⃣ **프롬프트 설계**\n",
    "- 구체적 지침의 효과\n",
    "- 환각 방지 기법\n",
    "- 일관된 출력 형식의 가치\n",
    "\n",
    "## 🚀 다음 단계 및 응용 방향\n",
    "\n",
    "### 🔧 시스템 개선 방향\n",
    "1. **하이브리드 검색**: BM25 + 벡터 검색 결합\n",
    "2. **리랭킹**: 검색 결과 재정렬로 정확도 향상\n",
    "3. **메타데이터 활용**: 문서 구조 정보 활용\n",
    "4. **다중 문서**: 여러 도메인 문서 통합\n",
    "\n",
    "### 📈 성능 최적화\n",
    "1. **캐싱**: 자주 묻는 질문 결과 저장\n",
    "2. **배치 처리**: 대량 쿼리 효율적 처리\n",
    "3. **모니터링**: 실시간 성능 추적\n",
    "4. **A/B 테스트**: 다양한 설정 비교\n",
    "\n",
    "### 🌐 실제 배포 고려사항\n",
    "1. **API 키 관리**: 보안과 사용량 제한\n",
    "2. **확장성**: 대용량 데이터와 사용자 처리\n",
    "3. **비용 최적화**: API 호출 최소화 전략\n",
    "4. **사용자 경험**: 응답 속도와 품질 균형\n",
    "\n",
    "## 🎯 실무 적용 아이디어\n",
    "\n",
    "### 📖 교육 분야\n",
    "- 교과서 기반 질의응답 시스템\n",
    "- 학습자 맞춤형 설명 생성\n",
    "- 시험 문제 자동 생성\n",
    "\n",
    "### 🏢 기업 업무\n",
    "- 사내 문서 검색 시스템\n",
    "- 고객 서비스 챗봇\n",
    "- 법규/정책 문서 분석\n",
    "\n",
    "### 🔬 연구 분야\n",
    "- 논문 요약 및 분석\n",
    "- 문헌 리뷰 자동화\n",
    "- 연구 동향 파악\n",
    "\n",
    "---\n",
    "\n",
    "## 🎊 축하합니다!\n",
    "\n",
    "**RAG 시스템의 핵심 개념부터 실제 구현까지 모든 과정을 완주하셨습니다!**\n",
    "\n",
    "이제 여러분은:\n",
    "- ✅ RAG 시스템의 동작 원리를 이해합니다\n",
    "- ✅ Google Gemini API를 활용할 수 있습니다\n",
    "- ✅ 벡터 데이터베이스를 구축할 수 있습니다\n",
    "- ✅ 프롬프트 엔지니어링을 할 수 있습니다\n",
    "- ✅ 실제 질의응답 시스템을 만들 수 있습니다\n",
    "\n",
    "**🚀 이제 여러분만의 RAG 시스템을 만들어보세요!**\n",
    "\n",
    "# 🎉 실무 활용 및 다음 단계\n",
    "\n",
    "## 🚀 RAG 시스템 실무 활용 사례\n",
    "\n",
    "### 💼 비즈니스 활용 분야\n",
    "\n",
    "| 분야 | 활용 사례 | 기대 효과 |\n",
    "|------|-----------|-----------|\n",
    "| **교육** | 학칙/규정 질의응답, 강의 자료 검색 | 학생 서비스 품질 향상 |\n",
    "| **의료** | 의료 가이드라인 검색, 환자 상담 지원 | 의료진 업무 효율성 증대 |\n",
    "| **법무** | 법령/판례 검색, 계약서 분석 | 법무 업무 자동화 |\n",
    "| **고객 서비스** | FAQ 자동 응답, 제품 매뉴얼 검색 | 고객 만족도 향상 |\n",
    "| **연구개발** | 논문 검색, 기술 문서 분석 | 연구 생산성 향상 |\n",
    "\n",
    "### 🔧 시스템 확장 방안\n",
    "\n",
    "**1. 멀티모달 RAG**\n",
    "```python\n",
    "# 텍스트 + 이미지 + 표 처리\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "loader = UnstructuredPDFLoader(\"document.pdf\", mode=\"elements\")\n",
    "```\n",
    "\n",
    "**2. 실시간 문서 업데이트**\n",
    "```python\n",
    "# 자동 재인덱싱 시스템\n",
    "import schedule\n",
    "schedule.every().day.at(\"02:00\").do(update_vector_database)\n",
    "```\n",
    "\n",
    "**3. 사용자 피드백 학습**\n",
    "```python\n",
    "# 사용자 평가를 통한 지속적 개선\n",
    "def collect_feedback(question, answer, rating):\n",
    "    # 피드백 저장 및 모델 개선에 활용\n",
    "    pass\n",
    "```\n",
    "\n",
    "## 📚 추가 학습 리소스\n",
    "\n",
    "### 📖 권장 도서\n",
    "- \"Building LLM Applications\" - Generative AI 실무\n",
    "- \"Retrieval-Augmented Generation for AI\" - RAG 심화\n",
    "- \"Prompt Engineering Guide\" - 프롬프트 최적화\n",
    "\n",
    "### 🌐 온라인 자료\n",
    "- [LangChain Documentation](https://python.langchain.com/)\n",
    "- [Google AI Studio](https://makersuite.google.com/)\n",
    "- [Chroma DB Cookbook](https://docs.trychroma.com/)\n",
    "- [RAG Papers Collection](https://github.com/hymie122/RAG-Survey)\n",
    "\n",
    "### 🛠️ 실습 프로젝트 아이디어\n",
    "\n",
    "1. **개인 문서 Assistant**: 개인 노트/논문을 활용한 지식 관리\n",
    "2. **회사 규정 Chatbot**: 내부 규정/매뉴얼 기반 질의응답\n",
    "3. **학습 Assistant**: 교재/강의록 기반 학습 도우미\n",
    "4. **코드 Documentation**: 코드베이스 기반 개발 가이드\n",
    "\n",
    "## 🔮 RAG 기술의 미래\n",
    "\n",
    "### 🌟 발전 방향\n",
    "- **멀티모달 통합**: 텍스트, 이미지, 음성, 비디오 통합 처리\n",
    "- **실시간 검색**: 웹 검색과 문서 검색의 하이브리드\n",
    "- **개인화**: 사용자별 맞춤형 검색 및 답변\n",
    "- **자가 개선**: AI가 스스로 성능을 향상시키는 시스템\n",
    "\n",
    "### 💡 새로운 도전과제\n",
    "- **정보 신뢰성**: 가짜 정보 식별 및 필터링\n",
    "- **편향성 제거**: 공정하고 균형잡힌 답변 생성\n",
    "- **프라이버시**: 민감한 정보 보호\n",
    "- **윤리적 AI**: 책임감 있는 AI 활용\n",
    "\n",
    "## 🎯 마무리\n",
    "\n",
    "축하합니다! 🎉 여러분은 이제 Google Gemini API를 활용한 완전한 RAG 시스템을 구축할 수 있게 되었습니다.\n",
    "\n",
    "### ✅ 학습한 내용\n",
    "- RAG의 핵심 개념과 원리\n",
    "- 문서 로딩부터 답변 생성까지 전체 파이프라인\n",
    "- 프롬프트 엔지니어링 기법\n",
    "- 시스템 평가 및 개선 방법\n",
    "\n",
    "### 🚀 다음 단계\n",
    "1. **다른 도메인 적용**: 자신만의 문서로 RAG 시스템 구축\n",
    "2. **성능 최적화**: 더 나은 청킹, 임베딩, 프롬프트 실험\n",
    "3. **웹 서비스화**: FastAPI나 Streamlit으로 웹 앱 개발\n",
    "4. **프로덕션 배포**: AWS, GCP 등 클라우드 서비스 활용\n",
    "\n",
    "RAG는 계속 발전하는 분야입니다. 지속적인 학습과 실험을 통해 더 나은 AI 시스템을 만들어가세요! 💪"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
